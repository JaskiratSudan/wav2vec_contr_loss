Setting up the environment...
Job started on gl1505.arc-ts.umich.edu at Tue Dec 30 16:42:10 EST 2025
Python version: Python 3.9.7
PyTorch version: 2.8.0+cu128
CUDA available: True
Current GPU: NVIDIA A40
----------------------------------------------------------------
EXPERIMENT NAME: supcon_uniformity_weight_0.1
Using BATCH_SIZE=32
=== CONFIG ===
MODEL_NAME=facebook/wav2vec2-xls-r-300m
SAVE_DIR=/home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m
TRAIN_ROOT=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_LA_train/flac
TRAIN_PROTOCOL=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_train_protocol_with_speaker.txt
DEV_ROOT=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_LA_dev/flac
DEV_PROTOCOL=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_dev_protocol_with_speaker.txt
TARGET_SAMPLE_RATE=16000
MAX_DURATION_SECONDS=5
INPUT_DIM=1024
HIDDEN_DIM=256
DROPOUT=0.1
EPOCHS=100
BATCH_SIZE=32
NUM_SAMPLES=None
HEAD_LR=0.005
ENC_LR=1e-05
WEIGHT_DECAY=0.003
TEMPERATURE=0.2
NUM_WORKERS=2
SEED=1337
UNIFORMITY_WEIGHT=0.1
UNIFORMITY_T=2.0
SUPCON_SIMILARITY=cosine
TOPK_NEG=15
WARMUP_EPOCHS=100
ALPHA_END=1.0
ALPHA_RAMP_EPOCHS=80
USE_RAWBOOST=True
RAWBOOST_PROB=0.7
FINETUNE_ENCODER=True
DISTRIBUTED=False | WORLD_SIZE=1 | RANK=0
=============
Using device: cuda | RawBoost=True (p=0.7)
CUDA device count: 1
[epoch 001] alpha=0.00 | train_loss=3.0254 | dev_loss=2.9550
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.9550)
[epoch 002] alpha=0.00 | train_loss=2.7267 | dev_loss=3.0700
[epoch 003] alpha=0.00 | train_loss=2.7154 | dev_loss=2.8156
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.8156)
[epoch 004] alpha=0.00 | train_loss=2.6882 | dev_loss=2.7982
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.7982)
[epoch 005] alpha=0.00 | train_loss=2.6788 | dev_loss=2.8672
[epoch 006] alpha=0.00 | train_loss=2.6809 | dev_loss=2.6948
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6948)
[epoch 007] alpha=0.00 | train_loss=2.6589 | dev_loss=2.7146
[epoch 008] alpha=0.00 | train_loss=2.6604 | dev_loss=2.6664
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6664)
[epoch 009] alpha=0.00 | train_loss=2.6573 | dev_loss=2.9408
[epoch 010] alpha=0.00 | train_loss=2.6662 | dev_loss=2.6370
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6370)
[epoch 011] alpha=0.00 | train_loss=2.6602 | dev_loss=2.6383
[epoch 012] alpha=0.00 | train_loss=2.6472 | dev_loss=2.6347
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6347)
[epoch 013] alpha=0.00 | train_loss=2.6469 | dev_loss=2.6370
[epoch 014] alpha=0.00 | train_loss=2.6479 | dev_loss=2.6318
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6318)
[epoch 015] alpha=0.00 | train_loss=2.6447 | dev_loss=2.6372
[epoch 016] alpha=0.00 | train_loss=2.6511 | dev_loss=2.6364
[epoch 017] alpha=0.00 | train_loss=2.6510 | dev_loss=2.6350
[epoch 018] alpha=0.00 | train_loss=2.6497 | dev_loss=2.6804
[epoch 019] alpha=0.00 | train_loss=2.6541 | dev_loss=2.6334
[epoch 020] alpha=0.00 | train_loss=2.6414 | dev_loss=2.6338
[epoch 021] alpha=0.00 | train_loss=2.6371 | dev_loss=2.6328
[epoch 022] alpha=0.00 | train_loss=2.6348 | dev_loss=2.6345
[epoch 023] alpha=0.00 | train_loss=2.6324 | dev_loss=2.6484
[epoch 024] alpha=0.00 | train_loss=2.6306 | dev_loss=2.6322
[epoch 025] alpha=0.00 | train_loss=2.6382 | dev_loss=2.6485
[epoch 026] alpha=0.00 | train_loss=2.6295 | dev_loss=2.6349
[epoch 027] alpha=0.00 | train_loss=2.6280 | dev_loss=2.6496
[epoch 028] alpha=0.00 | train_loss=2.6273 | dev_loss=2.6876
[epoch 029] alpha=0.00 | train_loss=2.6220 | dev_loss=2.6372
[epoch 030] alpha=0.00 | train_loss=2.6317 | dev_loss=2.6353
[epoch 031] alpha=0.00 | train_loss=2.6195 | dev_loss=2.6421
[epoch 032] alpha=0.00 | train_loss=2.6332 | dev_loss=2.6574
[epoch 033] alpha=0.00 | train_loss=2.6133 | dev_loss=2.6520
[epoch 034] alpha=0.00 | train_loss=2.6124 | dev_loss=2.6302
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6302)
[epoch 035] alpha=0.00 | train_loss=2.6256 | dev_loss=2.6475
[epoch 036] alpha=0.00 | train_loss=2.6119 | dev_loss=2.6308
[epoch 037] alpha=0.00 | train_loss=2.6187 | dev_loss=2.6415
[epoch 038] alpha=0.00 | train_loss=2.6062 | dev_loss=2.6589
[epoch 039] alpha=0.00 | train_loss=2.6053 | dev_loss=2.6383
[epoch 040] alpha=0.00 | train_loss=2.5980 | dev_loss=2.6394
[epoch 041] alpha=0.00 | train_loss=2.5994 | dev_loss=2.6326
[epoch 042] alpha=0.00 | train_loss=2.5981 | dev_loss=2.6469
[epoch 043] alpha=0.00 | train_loss=2.5901 | dev_loss=2.6421
[epoch 044] alpha=0.00 | train_loss=2.5884 | dev_loss=2.6488
[epoch 045] alpha=0.00 | train_loss=2.5730 | dev_loss=2.6430
[epoch 046] alpha=0.00 | train_loss=2.5765 | dev_loss=2.6561
[epoch 047] alpha=0.00 | train_loss=2.5711 | dev_loss=2.6435
[epoch 048] alpha=0.00 | train_loss=2.5625 | dev_loss=2.6827
[epoch 049] alpha=0.00 | train_loss=2.5591 | dev_loss=2.6721
[epoch 050] alpha=0.00 | train_loss=2.5614 | dev_loss=2.6669
[epoch 051] alpha=0.00 | train_loss=2.5615 | dev_loss=2.6739
[epoch 052] alpha=0.00 | train_loss=2.5548 | dev_loss=2.6676
[epoch 053] alpha=0.00 | train_loss=2.5498 | dev_loss=2.6612
[epoch 054] alpha=0.00 | train_loss=2.5440 | dev_loss=2.6694
[epoch 055] alpha=0.00 | train_loss=2.5329 | dev_loss=2.6641
[epoch 056] alpha=0.00 | train_loss=2.5305 | dev_loss=2.6574
[epoch 057] alpha=0.00 | train_loss=2.5367 | dev_loss=2.6511
[epoch 058] alpha=0.00 | train_loss=2.5391 | dev_loss=2.6599
[epoch 059] alpha=0.00 | train_loss=2.5325 | dev_loss=2.6720
[epoch 060] alpha=0.00 | train_loss=2.5276 | dev_loss=2.6577
[epoch 061] alpha=0.00 | train_loss=2.5297 | dev_loss=2.6469
[epoch 062] alpha=0.00 | train_loss=2.5178 | dev_loss=2.6666
[epoch 063] alpha=0.00 | train_loss=2.5313 | dev_loss=2.6512
[epoch 064] alpha=0.00 | train_loss=2.5168 | dev_loss=2.6606
[epoch 065] alpha=0.00 | train_loss=2.5167 | dev_loss=2.6593
[epoch 066] alpha=0.00 | train_loss=2.5179 | dev_loss=2.6650
[epoch 067] alpha=0.00 | train_loss=2.5085 | dev_loss=2.6704
[epoch 068] alpha=0.00 | train_loss=2.5048 | dev_loss=2.6615
[epoch 069] alpha=0.00 | train_loss=2.5038 | dev_loss=2.6636
[epoch 070] alpha=0.00 | train_loss=2.5116 | dev_loss=2.6663
[epoch 071] alpha=0.00 | train_loss=2.5061 | dev_loss=2.6584
[epoch 072] alpha=0.00 | train_loss=2.5097 | dev_loss=2.6607
[epoch 073] alpha=0.00 | train_loss=2.5002 | dev_loss=2.6683
[epoch 074] alpha=0.00 | train_loss=2.4993 | dev_loss=2.6601
[epoch 075] alpha=0.00 | train_loss=2.5005 | dev_loss=2.6749
[epoch 076] alpha=0.00 | train_loss=2.4979 | dev_loss=2.6594
[epoch 077] alpha=0.00 | train_loss=2.5014 | dev_loss=2.6507
[epoch 078] alpha=0.00 | train_loss=2.4973 | dev_loss=2.6789
[epoch 079] alpha=0.00 | train_loss=2.5090 | dev_loss=2.6134
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6134)
[epoch 080] alpha=0.00 | train_loss=2.5025 | dev_loss=2.6612
[epoch 081] alpha=0.00 | train_loss=2.4983 | dev_loss=2.6750
[epoch 082] alpha=0.00 | train_loss=2.4932 | dev_loss=2.6443
[epoch 083] alpha=0.00 | train_loss=2.4918 | dev_loss=2.6561
[epoch 084] alpha=0.00 | train_loss=2.4903 | dev_loss=2.6451
[epoch 085] alpha=0.00 | train_loss=2.4877 | dev_loss=2.6658
[epoch 086] alpha=0.00 | train_loss=2.4911 | dev_loss=2.6592
[epoch 087] alpha=0.00 | train_loss=2.4918 | dev_loss=2.6508
[epoch 088] alpha=0.00 | train_loss=2.4864 | dev_loss=2.6417
[epoch 089] alpha=0.00 | train_loss=2.4896 | dev_loss=2.6499
[epoch 090] alpha=0.00 | train_loss=2.4860 | dev_loss=2.6685
[epoch 091] alpha=0.00 | train_loss=2.4954 | dev_loss=2.6353
[epoch 092] alpha=0.00 | train_loss=2.4911 | dev_loss=2.6399
[epoch 093] alpha=0.00 | train_loss=2.4847 | dev_loss=2.6472
[epoch 094] alpha=0.00 | train_loss=2.4835 | dev_loss=2.6545
[epoch 095] alpha=0.00 | train_loss=2.4794 | dev_loss=2.6448
[epoch 096] alpha=0.00 | train_loss=2.4880 | dev_loss=2.6502
[epoch 097] alpha=0.00 | train_loss=2.4808 | dev_loss=2.6381
[epoch 098] alpha=0.00 | train_loss=2.4822 | dev_loss=2.6415
[epoch 099] alpha=0.00 | train_loss=2.4816 | dev_loss=2.6460
[epoch 100] alpha=0.00 | train_loss=2.4848 | dev_loss=2.6422
Best checkpoint: /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=2.6134)
/home/jsudan/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Using device: cuda
Model: facebook/wav2vec2-xls-r-300m
Checkpoint: /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt
Saving to: /home/jsudan/wav2vec_contr_loss/plots/dep_embeddings/ASV/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m
Loaded finetuned encoder weights from checkpoint.
Collecting embeddings on eval set...
/home/jsudan/myenv/lib/python3.9/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/jsudan/myenv/lib/python3.9/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12040. The TBB threading layer is disabled.
  warnings.warn(problem)
Invalid MIT-MAGIC-COOKIE-1 key  Processed 5120 samples...
  Processed 10240 samples...
  Processed 15360 samples...
  Processed 20480 samples...
  Processed 25600 samples...
  Processed 30720 samples...
  Processed 35840 samples...
  Processed 40960 samples...
  Processed 46080 samples...
  Processed 51200 samples...
  Processed 56320 samples...
  Processed 61440 samples...
  Processed 66560 samples...
Total eval embeddings: 71237 (dim=256)
Running UMAP...
Saving PNG plot...
Saved PNG: /home/jsudan/wav2vec_contr_loss/plots/dep_embeddings/ASV/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/stage1_umap_eval_by_attack.png
Saving interactive HTML plot...
Saved HTML: /home/jsudan/wav2vec_contr_loss/plots/dep_embeddings/ASV/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/stage1_umap_eval_by_attack.html
Done.
/home/jsudan/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Using device: cuda
Model: facebook/wav2vec2-xls-r-300m
Checkpoint: /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt
Saving to: /home/jsudan/wav2vec_contr_loss/plots/dep_embeddings/ITW/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m
Loaded finetuned encoder weights from checkpoint.
Collecting embeddings on ITW set...
/home/jsudan/myenv/lib/python3.9/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/home/jsudan/myenv/lib/python3.9/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12040. The TBB threading layer is disabled.
  warnings.warn(problem)
Invalid MIT-MAGIC-COOKIE-1 key  Processed 5120 samples...
  Processed 10240 samples...
  Processed 15360 samples...
  Processed 20480 samples...
  Processed 25600 samples...
  Processed 30720 samples...
Total ITW embeddings: 31779 (dim=256)
Running UMAP...
Saving PNG plot...
Saved PNG: /home/jsudan/wav2vec_contr_loss/plots/dep_embeddings/ITW/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/stage1_umap_itw_real_vs_spoof.png
Saving interactive HTML plot...
Saved HTML: /home/jsudan/wav2vec_contr_loss/plots/dep_embeddings/ITW/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/stage1_umap_itw_real_vs_spoof.html
Done.
/home/jsudan/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Using device: cuda
Loading Stage-1 checkpoint from: /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_uniformity_weight_0.1/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt
[OK] Loaded finetuned encoder weights from checkpoint.
==> Building ASV dataset for split: train
[ASV] Extracting train:   0%|          | 0/100 [00:00<?, ?it/s][ASV] Extracting train:   1%|          | 1/100 [00:07<13:11,  7.99s/it][ASV] Extracting train:   2%|▏         | 2/100 [00:11<08:20,  5.10s/it][ASV] Extracting train:   3%|▎         | 3/100 [00:14<06:46,  4.19s/it][ASV] Extracting train:   4%|▍         | 4/100 [00:17<06:00,  3.75s/it][ASV] Extracting train:   5%|▌         | 5/100 [00:20<05:34,  3.52s/it][ASV] Extracting train:   6%|▌         | 6/100 [00:23<05:17,  3.37s/it][ASV] Extracting train:   7%|▋         | 7/100 [00:26<05:05,  3.28s/it][ASV] Extracting train:   8%|▊         | 8/100 [00:29<04:56,  3.22s/it][ASV] Extracting train:   9%|▉         | 9/100 [00:32<04:49,  3.19s/it][ASV] Extracting train:  10%|█         | 10/100 [00:35<04:44,  3.16s/it][ASV] Extracting train:  11%|█         | 11/100 [00:38<04:39,  3.14s/it][ASV] Extracting train:  12%|█▏        | 12/100 [00:42<04:35,  3.13s/it][ASV] Extracting train:  13%|█▎        | 13/100 [00:45<04:32,  3.13s/it][ASV] Extracting train:  14%|█▍        | 14/100 [00:48<04:28,  3.13s/it][ASV] Extracting train:  15%|█▌        | 15/100 [00:51<04:25,  3.13s/it][ASV] Extracting train:  16%|█▌        | 16/100 [00:54<04:22,  3.13s/it][ASV] Extracting train:  17%|█▋        | 17/100 [00:57<04:19,  3.13s/it][ASV] Extracting train:  18%|█▊        | 18/100 [01:00<04:16,  3.13s/it][ASV] Extracting train:  19%|█▉        | 19/100 [01:03<04:13,  3.13s/it][ASV] Extracting train:  20%|██        | 20/100 [01:07<04:10,  3.13s/it][ASV] Extracting train:  21%|██        | 21/100 [01:10<04:07,  3.13s/it][ASV] Extracting train:  22%|██▏       | 22/100 [01:13<04:04,  3.13s/it][ASV] Extracting train:  23%|██▎       | 23/100 [01:16<04:00,  3.13s/it][ASV] Extracting train:  24%|██▍       | 24/100 [01:19<03:57,  3.13s/it][ASV] Extracting train:  25%|██▌       | 25/100 [01:22<03:55,  3.13s/it][ASV] Extracting train:  26%|██▌       | 26/100 [01:25<03:52,  3.14s/it][ASV] Extracting train:  27%|██▋       | 27/100 [01:29<03:49,  3.14s/it][ASV] Extracting train:  28%|██▊       | 28/100 [01:32<03:46,  3.14s/it][ASV] Extracting train:  29%|██▉       | 29/100 [01:35<03:43,  3.15s/it][ASV] Extracting train:  30%|███       | 30/100 [01:38<03:40,  3.15s/it][ASV] Extracting train:  31%|███       | 31/100 [01:41<03:37,  3.15s/it][ASV] Extracting train:  32%|███▏      | 32/100 [01:44<03:34,  3.15s/it][ASV] Extracting train:  33%|███▎      | 33/100 [01:47<03:31,  3.15s/it][ASV] Extracting train:  34%|███▍      | 34/100 [01:51<03:27,  3.15s/it][ASV] Extracting train:  35%|███▌      | 35/100 [01:54<03:24,  3.15s/it][ASV] Extracting train:  36%|███▌      | 36/100 [01:57<03:21,  3.15s/it][ASV] Extracting train:  37%|███▋      | 37/100 [02:00<03:18,  3.15s/it][ASV] Extracting train:  38%|███▊      | 38/100 [02:03<03:15,  3.15s/it][ASV] Extracting train:  39%|███▉      | 39/100 [02:06<03:12,  3.15s/it][ASV] Extracting train:  40%|████      | 40/100 [02:10<03:08,  3.15s/it][ASV] Extracting train:  41%|████      | 41/100 [02:13<03:05,  3.15s/it][ASV] Extracting train:  42%|████▏     | 42/100 [02:16<03:02,  3.15s/it][ASV] Extracting train:  43%|████▎     | 43/100 [02:19<02:59,  3.15s/it][ASV] Extracting train:  44%|████▍     | 44/100 [02:22<02:56,  3.15s/it][ASV] Extracting train:  45%|████▌     | 45/100 [02:25<02:52,  3.14s/it][ASV] Extracting train:  46%|████▌     | 46/100 [02:28<02:49,  3.14s/it][ASV] Extracting train:  47%|████▋     | 47/100 [02:32<02:46,  3.14s/it][ASV] Extracting train:  48%|████▊     | 48/100 [02:35<02:43,  3.14s/it][ASV] Extracting train:  49%|████▉     | 49/100 [02:38<02:40,  3.14s/it][ASV] Extracting train:  50%|█████     | 50/100 [02:41<02:37,  3.14s/it][ASV] Extracting train:  51%|█████     | 51/100 [02:44<02:33,  3.14s/it][ASV] Extracting train:  52%|█████▏    | 52/100 [02:47<02:30,  3.14s/it][ASV] Extracting train:  53%|█████▎    | 53/100 [02:50<02:27,  3.14s/it][ASV] Extracting train:  54%|█████▍    | 54/100 [02:53<02:24,  3.14s/it][ASV] Extracting train:  55%|█████▌    | 55/100 [02:57<02:21,  3.14s/it][ASV] Extracting train:  56%|█████▌    | 56/100 [03:00<02:18,  3.14s/it][ASV] Extracting train:  57%|█████▋    | 57/100 [03:03<02:15,  3.14s/it][ASV] Extracting train:  58%|█████▊    | 58/100 [03:06<02:11,  3.14s/it][ASV] Extracting train:  59%|█████▉    | 59/100 [03:09<02:08,  3.14s/it][ASV] Extracting train:  60%|██████    | 60/100 [03:12<02:05,  3.14s/it][ASV] Extracting train:  61%|██████    | 61/100 [03:15<02:02,  3.14s/it][ASV] Extracting train:  62%|██████▏   | 62/100 [03:19<01:59,  3.14s/it][ASV] Extracting train:  63%|██████▎   | 63/100 [03:22<01:56,  3.14s/it][ASV] Extracting train:  64%|██████▍   | 64/100 [03:25<01:53,  3.14s/it][ASV] Extracting train:  65%|██████▌   | 65/100 [03:28<01:49,  3.14s/it][ASV] Extracting train:  66%|██████▌   | 66/100 [03:31<01:46,  3.14s/it][ASV] Extracting train:  67%|██████▋   | 67/100 [03:34<01:43,  3.14s/it][ASV] Extracting train:  68%|██████▊   | 68/100 [03:37<01:40,  3.14s/it][ASV] Extracting train:  69%|██████▉   | 69/100 [03:41<01:37,  3.14s/it][ASV] Extracting train:  70%|███████   | 70/100 [03:44<01:34,  3.14s/it][ASV] Extracting train:  71%|███████   | 71/100 [03:47<01:31,  3.15s/it][ASV] Extracting train:  72%|███████▏  | 72/100 [03:50<01:28,  3.15s/it][ASV] Extracting train:  73%|███████▎  | 73/100 [03:53<01:24,  3.14s/it][ASV] Extracting train:  74%|███████▍  | 74/100 [03:56<01:21,  3.15s/it][ASV] Extracting train:  75%|███████▌  | 75/100 [04:00<01:18,  3.15s/it][ASV] Extracting train:  76%|███████▌  | 76/100 [04:03<01:15,  3.15s/it][ASV] Extracting train:  77%|███████▋  | 77/100 [04:06<01:12,  3.15s/it][ASV] Extracting train:  78%|███████▊  | 78/100 [04:09<01:09,  3.15s/it][ASV] Extracting train:  79%|███████▉  | 79/100 [04:12<01:06,  3.15s/it][ASV] Extracting train:  80%|████████  | 80/100 [04:15<01:02,  3.15s/it][ASV] Extracting train:  81%|████████  | 81/100 [04:18<00:59,  3.14s/it][ASV] Extracting train:  82%|████████▏ | 82/100 [04:22<00:56,  3.14s/it][ASV] Extracting train:  83%|████████▎ | 83/100 [04:25<00:53,  3.14s/it][ASV] Extracting train:  84%|████████▍ | 84/100 [04:28<00:50,  3.15s/it][ASV] Extracting train:  85%|████████▌ | 85/100 [04:31<00:47,  3.15s/it][ASV] Extracting train:  86%|████████▌ | 86/100 [04:34<00:44,  3.15s/it][ASV] Extracting train:  87%|████████▋ | 87/100 [04:37<00:40,  3.15s/it][ASV] Extracting train:  88%|████████▊ | 88/100 [04:40<00:37,  3.15s/it][ASV] Extracting train:  89%|████████▉ | 89/100 [04:44<00:34,  3.15s/it][ASV] Extracting train:  90%|█████████ | 90/100 [04:47<00:31,  3.15s/it][ASV] Extracting train:  91%|█████████ | 91/100 [04:50<00:28,  3.15s/it][ASV] Extracting train:  92%|█████████▏| 92/100 [04:53<00:25,  3.15s/it][ASV] Extracting train:  93%|█████████▎| 93/100 [04:56<00:22,  3.15s/it][ASV] Extracting train:  94%|█████████▍| 94/100 [04:59<00:18,  3.15s/it][ASV] Extracting train:  95%|█████████▌| 95/100 [05:02<00:15,  3.15s/it][ASV] Extracting train:  96%|█████████▌| 96/100 [05:06<00:12,  3.14s/it][ASV] Extracting train:  97%|█████████▋| 97/100 [05:09<00:09,  3.14s/it][ASV] Extracting train:  98%|█████████▊| 98/100 [05:12<00:06,  3.14s/it][ASV] Extracting train:  99%|█████████▉| 99/100 [05:15<00:03,  3.15s/it][ASV] Extracting train: 100%|██████████| 100/100 [05:15<00:00,  2.34s/it][ASV] Extracting train: 100%|██████████| 100/100 [05:16<00:00,  3.16s/it]
[OK][ASV] Saved train: embeddings (25380, 256), labels (25380,)
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/train_embeddings.npy
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/train_labels.npy
==> Building ASV dataset for split: dev
[ASV] Extracting dev:   0%|          | 0/98 [00:00<?, ?it/s][ASV] Extracting dev:   1%|          | 1/98 [00:07<11:45,  7.28s/it][ASV] Extracting dev:   2%|▏         | 2/98 [00:10<07:44,  4.84s/it][ASV] Extracting dev:   3%|▎         | 3/98 [00:13<06:25,  4.06s/it][ASV] Extracting dev:   4%|▍         | 4/98 [00:16<05:47,  3.70s/it][ASV] Extracting dev:   5%|▌         | 5/98 [00:19<05:25,  3.50s/it][ASV] Extracting dev:   6%|▌         | 6/98 [00:22<05:10,  3.38s/it][ASV] Extracting dev:   7%|▋         | 7/98 [00:26<05:00,  3.30s/it][ASV] Extracting dev:   8%|▊         | 8/98 [00:29<04:52,  3.25s/it][ASV] Extracting dev:   9%|▉         | 9/98 [00:32<04:46,  3.22s/it][ASV] Extracting dev:  10%|█         | 10/98 [00:35<04:41,  3.20s/it][ASV] Extracting dev:  11%|█         | 11/98 [00:38<04:36,  3.18s/it][ASV] Extracting dev:  12%|█▏        | 12/98 [00:41<04:32,  3.16s/it][ASV] Extracting dev:  13%|█▎        | 13/98 [00:44<04:28,  3.15s/it][ASV] Extracting dev:  14%|█▍        | 14/98 [00:48<04:24,  3.15s/it][ASV] Extracting dev:  15%|█▌        | 15/98 [00:51<04:20,  3.14s/it][ASV] Extracting dev:  16%|█▋        | 16/98 [00:54<04:17,  3.14s/it][ASV] Extracting dev:  17%|█▋        | 17/98 [00:57<04:14,  3.14s/it][ASV] Extracting dev:  18%|█▊        | 18/98 [01:00<04:11,  3.14s/it][ASV] Extracting dev:  19%|█▉        | 19/98 [01:03<04:07,  3.14s/it][ASV] Extracting dev:  20%|██        | 20/98 [01:06<04:04,  3.14s/it][ASV] Extracting dev:  21%|██▏       | 21/98 [01:10<04:01,  3.14s/it][ASV] Extracting dev:  22%|██▏       | 22/98 [01:13<03:58,  3.14s/it][ASV] Extracting dev:  23%|██▎       | 23/98 [01:16<03:55,  3.14s/it][ASV] Extracting dev:  24%|██▍       | 24/98 [01:19<03:52,  3.14s/it][ASV] Extracting dev:  26%|██▌       | 25/98 [01:22<03:49,  3.14s/it][ASV] Extracting dev:  27%|██▋       | 26/98 [01:25<03:46,  3.14s/it][ASV] Extracting dev:  28%|██▊       | 27/98 [01:28<03:43,  3.15s/it][ASV] Extracting dev:  29%|██▊       | 28/98 [01:32<03:40,  3.15s/it][ASV] Extracting dev:  30%|██▉       | 29/98 [01:35<03:37,  3.15s/it][ASV] Extracting dev:  31%|███       | 30/98 [01:38<03:34,  3.15s/it][ASV] Extracting dev:  32%|███▏      | 31/98 [01:41<03:31,  3.15s/it][ASV] Extracting dev:  33%|███▎      | 32/98 [01:44<03:27,  3.15s/it][ASV] Extracting dev:  34%|███▎      | 33/98 [01:47<03:24,  3.15s/it][ASV] Extracting dev:  35%|███▍      | 34/98 [01:50<03:21,  3.15s/it][ASV] Extracting dev:  36%|███▌      | 35/98 [01:54<03:18,  3.15s/it][ASV] Extracting dev:  37%|███▋      | 36/98 [01:57<03:15,  3.15s/it][ASV] Extracting dev:  38%|███▊      | 37/98 [02:00<03:12,  3.15s/it][ASV] Extracting dev:  39%|███▉      | 38/98 [02:03<03:09,  3.15s/it][ASV] Extracting dev:  40%|███▉      | 39/98 [02:06<03:05,  3.15s/it][ASV] Extracting dev:  41%|████      | 40/98 [02:09<03:02,  3.15s/it][ASV] Extracting dev:  42%|████▏     | 41/98 [02:12<02:59,  3.15s/it][ASV] Extracting dev:  43%|████▎     | 42/98 [02:16<02:56,  3.14s/it][ASV] Extracting dev:  44%|████▍     | 43/98 [02:19<02:52,  3.14s/it][ASV] Extracting dev:  45%|████▍     | 44/98 [02:22<02:49,  3.14s/it][ASV] Extracting dev:  46%|████▌     | 45/98 [02:25<02:46,  3.14s/it][ASV] Extracting dev:  47%|████▋     | 46/98 [02:28<02:43,  3.14s/it][ASV] Extracting dev:  48%|████▊     | 47/98 [02:31<02:40,  3.14s/it][ASV] Extracting dev:  49%|████▉     | 48/98 [02:34<02:37,  3.15s/it][ASV] Extracting dev:  50%|█████     | 49/98 [02:38<02:34,  3.15s/it][ASV] Extracting dev:  51%|█████     | 50/98 [02:41<02:30,  3.14s/it][ASV] Extracting dev:  52%|█████▏    | 51/98 [02:44<02:27,  3.14s/it][ASV] Extracting dev:  53%|█████▎    | 52/98 [02:47<02:24,  3.14s/it][ASV] Extracting dev:  54%|█████▍    | 53/98 [02:50<02:21,  3.14s/it][ASV] Extracting dev:  55%|█████▌    | 54/98 [02:53<02:18,  3.14s/it][ASV] Extracting dev:  56%|█████▌    | 55/98 [02:56<02:15,  3.14s/it][ASV] Extracting dev:  57%|█████▋    | 56/98 [03:00<02:11,  3.14s/it][ASV] Extracting dev:  58%|█████▊    | 57/98 [03:03<02:08,  3.14s/it][ASV] Extracting dev:  59%|█████▉    | 58/98 [03:06<02:05,  3.14s/it][ASV] Extracting dev:  60%|██████    | 59/98 [03:09<02:02,  3.14s/it][ASV] Extracting dev:  61%|██████    | 60/98 [03:12<01:59,  3.14s/it][ASV] Extracting dev:  62%|██████▏   | 61/98 [03:15<01:56,  3.14s/it][ASV] Extracting dev:  63%|██████▎   | 62/98 [03:18<01:53,  3.14s/it][ASV] Extracting dev:  64%|██████▍   | 63/98 [03:22<01:50,  3.14s/it][ASV] Extracting dev:  65%|██████▌   | 64/98 [03:25<01:46,  3.14s/it][ASV] Extracting dev:  66%|██████▋   | 65/98 [03:28<01:43,  3.14s/it][ASV] Extracting dev:  67%|██████▋   | 66/98 [03:31<01:40,  3.14s/it][ASV] Extracting dev:  68%|██████▊   | 67/98 [03:34<01:37,  3.14s/it][ASV] Extracting dev:  69%|██████▉   | 68/98 [03:37<01:34,  3.14s/it][ASV] Extracting dev:  70%|███████   | 69/98 [03:40<01:31,  3.15s/it][ASV] Extracting dev:  71%|███████▏  | 70/98 [03:44<01:28,  3.15s/it][ASV] Extracting dev:  72%|███████▏  | 71/98 [03:47<01:24,  3.15s/it][ASV] Extracting dev:  73%|███████▎  | 72/98 [03:50<01:21,  3.14s/it][ASV] Extracting dev:  74%|███████▍  | 73/98 [03:53<01:18,  3.15s/it][ASV] Extracting dev:  76%|███████▌  | 74/98 [03:56<01:15,  3.15s/it][ASV] Extracting dev:  77%|███████▋  | 75/98 [03:59<01:12,  3.15s/it][ASV] Extracting dev:  78%|███████▊  | 76/98 [04:03<01:09,  3.15s/it][ASV] Extracting dev:  79%|███████▊  | 77/98 [04:06<01:06,  3.15s/it][ASV] Extracting dev:  80%|███████▉  | 78/98 [04:09<01:02,  3.15s/it][ASV] Extracting dev:  81%|████████  | 79/98 [04:12<00:59,  3.15s/it][ASV] Extracting dev:  82%|████████▏ | 80/98 [04:15<00:56,  3.15s/it][ASV] Extracting dev:  83%|████████▎ | 81/98 [04:18<00:53,  3.15s/it][ASV] Extracting dev:  84%|████████▎ | 82/98 [04:21<00:50,  3.15s/it][ASV] Extracting dev:  85%|████████▍ | 83/98 [04:25<00:47,  3.15s/it][ASV] Extracting dev:  86%|████████▌ | 84/98 [04:28<00:44,  3.15s/it][ASV] Extracting dev:  87%|████████▋ | 85/98 [04:31<00:40,  3.15s/it][ASV] Extracting dev:  88%|████████▊ | 86/98 [04:34<00:37,  3.15s/it][ASV] Extracting dev:  89%|████████▉ | 87/98 [04:37<00:34,  3.15s/it][ASV] Extracting dev:  90%|████████▉ | 88/98 [04:40<00:31,  3.15s/it][ASV] Extracting dev:  91%|█████████ | 89/98 [04:43<00:28,  3.15s/it][ASV] Extracting dev:  92%|█████████▏| 90/98 [04:47<00:25,  3.15s/it][ASV] Extracting dev:  93%|█████████▎| 91/98 [04:50<00:22,  3.15s/it][ASV] Extracting dev:  94%|█████████▍| 92/98 [04:53<00:18,  3.15s/it][ASV] Extracting dev:  95%|█████████▍| 93/98 [04:56<00:15,  3.15s/it][ASV] Extracting dev:  96%|█████████▌| 94/98 [04:59<00:12,  3.15s/it][ASV] Extracting dev:  97%|█████████▋| 95/98 [05:02<00:09,  3.15s/it][ASV] Extracting dev:  98%|█████████▊| 96/98 [05:05<00:06,  3.15s/it][ASV] Extracting dev:  99%|█████████▉| 97/98 [05:09<00:03,  3.15s/it][ASV] Extracting dev: 100%|██████████| 98/98 [05:09<00:00,  2.26s/it][ASV] Extracting dev: 100%|██████████| 98/98 [05:09<00:00,  3.16s/it]
[OK][ASV] Saved dev: embeddings (24844, 256), labels (24844,)
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/dev_embeddings.npy
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/dev_labels.npy
==> Building ASV dataset for split: eval
[ASV] Extracting eval:   0%|          | 0/279 [00:00<?, ?it/s][ASV] Extracting eval:   0%|          | 1/279 [00:06<30:48,  6.65s/it][ASV] Extracting eval:   1%|          | 2/279 [00:09<21:08,  4.58s/it][ASV] Extracting eval:   1%|          | 3/279 [00:12<18:01,  3.92s/it][ASV] Extracting eval:   1%|▏         | 4/279 [00:16<16:32,  3.61s/it][ASV] Extracting eval:   2%|▏         | 5/279 [00:19<15:41,  3.44s/it][ASV] Extracting eval:   2%|▏         | 6/279 [00:22<15:10,  3.33s/it][ASV] Extracting eval:   3%|▎         | 7/279 [00:25<14:49,  3.27s/it][ASV] Extracting eval:   3%|▎         | 8/279 [00:28<14:34,  3.23s/it][ASV] Extracting eval:   3%|▎         | 9/279 [00:31<14:24,  3.20s/it][ASV] Extracting eval:   4%|▎         | 10/279 [00:34<14:15,  3.18s/it][ASV] Extracting eval:   4%|▍         | 11/279 [00:38<14:09,  3.17s/it][ASV] Extracting eval:   4%|▍         | 12/279 [00:41<14:03,  3.16s/it][ASV] Extracting eval:   5%|▍         | 13/279 [00:44<13:58,  3.15s/it][ASV] Extracting eval:   5%|▌         | 14/279 [00:47<13:54,  3.15s/it][ASV] Extracting eval:   5%|▌         | 15/279 [00:50<13:50,  3.15s/it][ASV] Extracting eval:   6%|▌         | 16/279 [00:53<13:46,  3.14s/it][ASV] Extracting eval:   6%|▌         | 17/279 [00:56<13:43,  3.14s/it][ASV] Extracting eval:   6%|▋         | 18/279 [00:59<13:40,  3.14s/it][ASV] Extracting eval:   7%|▋         | 19/279 [01:03<13:36,  3.14s/it][ASV] Extracting eval:   7%|▋         | 20/279 [01:06<13:33,  3.14s/it][ASV] Extracting eval:   8%|▊         | 21/279 [01:09<13:30,  3.14s/it][ASV] Extracting eval:   8%|▊         | 22/279 [01:12<13:27,  3.14s/it][ASV] Extracting eval:   8%|▊         | 23/279 [01:15<13:24,  3.14s/it][ASV] Extracting eval:   9%|▊         | 24/279 [01:18<13:21,  3.14s/it][ASV] Extracting eval:   9%|▉         | 25/279 [01:21<13:18,  3.14s/it][ASV] Extracting eval:   9%|▉         | 26/279 [01:25<13:14,  3.14s/it][ASV] Extracting eval:  10%|▉         | 27/279 [01:28<13:11,  3.14s/it][ASV] Extracting eval:  10%|█         | 28/279 [01:31<13:08,  3.14s/it][ASV] Extracting eval:  10%|█         | 29/279 [01:34<13:05,  3.14s/it][ASV] Extracting eval:  11%|█         | 30/279 [01:37<13:02,  3.14s/it][ASV] Extracting eval:  11%|█         | 31/279 [01:40<12:59,  3.14s/it][ASV] Extracting eval:  11%|█▏        | 32/279 [01:43<12:56,  3.14s/it][ASV] Extracting eval:  12%|█▏        | 33/279 [01:47<12:53,  3.14s/it][ASV] Extracting eval:  12%|█▏        | 34/279 [01:50<12:49,  3.14s/it][ASV] Extracting eval:  13%|█▎        | 35/279 [01:53<12:47,  3.14s/it][ASV] Extracting eval:  13%|█▎        | 36/279 [01:56<12:43,  3.14s/it][ASV] Extracting eval:  13%|█▎        | 37/279 [01:59<12:40,  3.14s/it][ASV] Extracting eval:  14%|█▎        | 38/279 [02:02<12:37,  3.14s/it][ASV] Extracting eval:  14%|█▍        | 39/279 [02:05<12:33,  3.14s/it][ASV] Extracting eval:  14%|█▍        | 40/279 [02:09<12:30,  3.14s/it][ASV] Extracting eval:  15%|█▍        | 41/279 [02:12<12:27,  3.14s/it][ASV] Extracting eval:  15%|█▌        | 42/279 [02:15<12:24,  3.14s/it][ASV] Extracting eval:  15%|█▌        | 43/279 [02:18<12:21,  3.14s/it][ASV] Extracting eval:  16%|█▌        | 44/279 [02:21<12:18,  3.14s/it][ASV] Extracting eval:  16%|█▌        | 45/279 [02:24<12:14,  3.14s/it][ASV] Extracting eval:  16%|█▋        | 46/279 [02:27<12:11,  3.14s/it][ASV] Extracting eval:  17%|█▋        | 47/279 [02:31<12:08,  3.14s/it][ASV] Extracting eval:  17%|█▋        | 48/279 [02:34<12:05,  3.14s/it][ASV] Extracting eval:  18%|█▊        | 49/279 [02:37<12:02,  3.14s/it][ASV] Extracting eval:  18%|█▊        | 50/279 [02:40<11:59,  3.14s/it][ASV] Extracting eval:  18%|█▊        | 51/279 [02:43<11:56,  3.14s/it][ASV] Extracting eval:  19%|█▊        | 52/279 [02:46<11:52,  3.14s/it][ASV] Extracting eval:  19%|█▉        | 53/279 [02:49<11:49,  3.14s/it][ASV] Extracting eval:  19%|█▉        | 54/279 [02:53<11:46,  3.14s/it][ASV] Extracting eval:  20%|█▉        | 55/279 [02:56<11:43,  3.14s/it][ASV] Extracting eval:  20%|██        | 56/279 [02:59<11:40,  3.14s/it][ASV] Extracting eval:  20%|██        | 57/279 [03:02<11:37,  3.14s/it][ASV] Extracting eval:  21%|██        | 58/279 [03:05<11:34,  3.14s/it][ASV] Extracting eval:  21%|██        | 59/279 [03:08<11:30,  3.14s/it][ASV] Extracting eval:  22%|██▏       | 60/279 [03:11<11:27,  3.14s/it][ASV] Extracting eval:  22%|██▏       | 61/279 [03:15<11:24,  3.14s/it][ASV] Extracting eval:  22%|██▏       | 62/279 [03:18<11:21,  3.14s/it][ASV] Extracting eval:  23%|██▎       | 63/279 [03:21<11:18,  3.14s/it][ASV] Extracting eval:  23%|██▎       | 64/279 [03:24<11:15,  3.14s/it][ASV] Extracting eval:  23%|██▎       | 65/279 [03:27<11:11,  3.14s/it][ASV] Extracting eval:  24%|██▎       | 66/279 [03:30<11:09,  3.14s/it][ASV] Extracting eval:  24%|██▍       | 67/279 [03:33<11:06,  3.14s/it][ASV] Extracting eval:  24%|██▍       | 68/279 [03:37<11:02,  3.14s/it][ASV] Extracting eval:  25%|██▍       | 69/279 [03:40<10:59,  3.14s/it][ASV] Extracting eval:  25%|██▌       | 70/279 [03:43<10:56,  3.14s/it][ASV] Extracting eval:  25%|██▌       | 71/279 [03:46<10:53,  3.14s/it][ASV] Extracting eval:  26%|██▌       | 72/279 [03:49<10:50,  3.14s/it][ASV] Extracting eval:  26%|██▌       | 73/279 [03:52<10:47,  3.14s/it][ASV] Extracting eval:  27%|██▋       | 74/279 [03:55<10:43,  3.14s/it][ASV] Extracting eval:  27%|██▋       | 75/279 [03:59<10:41,  3.14s/it][ASV] Extracting eval:  27%|██▋       | 76/279 [04:02<10:37,  3.14s/it][ASV] Extracting eval:  28%|██▊       | 77/279 [04:05<10:34,  3.14s/it][ASV] Extracting eval:  28%|██▊       | 78/279 [04:08<10:31,  3.14s/it][ASV] Extracting eval:  28%|██▊       | 79/279 [04:11<10:28,  3.14s/it][ASV] Extracting eval:  29%|██▊       | 80/279 [04:14<10:25,  3.14s/it][ASV] Extracting eval:  29%|██▉       | 81/279 [04:17<10:22,  3.14s/it][ASV] Extracting eval:  29%|██▉       | 82/279 [04:21<10:18,  3.14s/it][ASV] Extracting eval:  30%|██▉       | 83/279 [04:24<10:15,  3.14s/it][ASV] Extracting eval:  30%|███       | 84/279 [04:27<10:12,  3.14s/it][ASV] Extracting eval:  30%|███       | 85/279 [04:30<10:09,  3.14s/it][ASV] Extracting eval:  31%|███       | 86/279 [04:33<10:06,  3.14s/it][ASV] Extracting eval:  31%|███       | 87/279 [04:36<10:03,  3.14s/it][ASV] Extracting eval:  32%|███▏      | 88/279 [04:39<09:59,  3.14s/it][ASV] Extracting eval:  32%|███▏      | 89/279 [04:42<09:56,  3.14s/it][ASV] Extracting eval:  32%|███▏      | 90/279 [04:46<09:53,  3.14s/it][ASV] Extracting eval:  33%|███▎      | 91/279 [04:49<09:50,  3.14s/it][ASV] Extracting eval:  33%|███▎      | 92/279 [04:52<09:47,  3.14s/it][ASV] Extracting eval:  33%|███▎      | 93/279 [04:55<09:43,  3.14s/it][ASV] Extracting eval:  34%|███▎      | 94/279 [04:58<09:40,  3.14s/it][ASV] Extracting eval:  34%|███▍      | 95/279 [05:01<09:37,  3.14s/it][ASV] Extracting eval:  34%|███▍      | 96/279 [05:04<09:34,  3.14s/it][ASV] Extracting eval:  35%|███▍      | 97/279 [05:08<09:31,  3.14s/it][ASV] Extracting eval:  35%|███▌      | 98/279 [05:11<09:28,  3.14s/it][ASV] Extracting eval:  35%|███▌      | 99/279 [05:14<09:25,  3.14s/it][ASV] Extracting eval:  36%|███▌      | 100/279 [05:17<09:22,  3.14s/it][ASV] Extracting eval:  36%|███▌      | 101/279 [05:20<09:19,  3.14s/it][ASV] Extracting eval:  37%|███▋      | 102/279 [05:23<09:15,  3.14s/it][ASV] Extracting eval:  37%|███▋      | 103/279 [05:26<09:12,  3.14s/it][ASV] Extracting eval:  37%|███▋      | 104/279 [05:30<09:09,  3.14s/it][ASV] Extracting eval:  38%|███▊      | 105/279 [05:33<09:06,  3.14s/it][ASV] Extracting eval:  38%|███▊      | 106/279 [05:36<09:03,  3.14s/it][ASV] Extracting eval:  38%|███▊      | 107/279 [05:39<09:00,  3.14s/it][ASV] Extracting eval:  39%|███▊      | 108/279 [05:42<08:56,  3.14s/it][ASV] Extracting eval:  39%|███▉      | 109/279 [05:45<08:53,  3.14s/it][ASV] Extracting eval:  39%|███▉      | 110/279 [05:48<08:50,  3.14s/it][ASV] Extracting eval:  40%|███▉      | 111/279 [05:52<08:47,  3.14s/it][ASV] Extracting eval:  40%|████      | 112/279 [05:55<08:44,  3.14s/it][ASV] Extracting eval:  41%|████      | 113/279 [05:58<08:41,  3.14s/it][ASV] Extracting eval:  41%|████      | 114/279 [06:01<08:38,  3.14s/it][ASV] Extracting eval:  41%|████      | 115/279 [06:04<08:34,  3.14s/it][ASV] Extracting eval:  42%|████▏     | 116/279 [06:07<08:31,  3.14s/it][ASV] Extracting eval:  42%|████▏     | 117/279 [06:10<08:28,  3.14s/it][ASV] Extracting eval:  42%|████▏     | 118/279 [06:14<08:25,  3.14s/it][ASV] Extracting eval:  43%|████▎     | 119/279 [06:17<08:22,  3.14s/it][ASV] Extracting eval:  43%|████▎     | 120/279 [06:20<08:19,  3.14s/it][ASV] Extracting eval:  43%|████▎     | 121/279 [06:23<08:16,  3.14s/it][ASV] Extracting eval:  44%|████▎     | 122/279 [06:26<08:13,  3.14s/it][ASV] Extracting eval:  44%|████▍     | 123/279 [06:29<08:10,  3.14s/it][ASV] Extracting eval:  44%|████▍     | 124/279 [06:32<08:06,  3.14s/it][ASV] Extracting eval:  45%|████▍     | 125/279 [06:36<08:03,  3.14s/it][ASV] Extracting eval:  45%|████▌     | 126/279 [06:39<08:00,  3.14s/it][ASV] Extracting eval:  46%|████▌     | 127/279 [06:42<07:57,  3.14s/it][ASV] Extracting eval:  46%|████▌     | 128/279 [06:45<07:54,  3.14s/it][ASV] Extracting eval:  46%|████▌     | 129/279 [06:48<07:50,  3.14s/it][ASV] Extracting eval:  47%|████▋     | 130/279 [06:51<07:47,  3.14s/it][ASV] Extracting eval:  47%|████▋     | 131/279 [06:54<07:44,  3.14s/it][ASV] Extracting eval:  47%|████▋     | 132/279 [06:58<07:41,  3.14s/it][ASV] Extracting eval:  48%|████▊     | 133/279 [07:01<07:38,  3.14s/it][ASV] Extracting eval:  48%|████▊     | 134/279 [07:04<07:35,  3.14s/it][ASV] Extracting eval:  48%|████▊     | 135/279 [07:07<07:32,  3.14s/it][ASV] Extracting eval:  49%|████▊     | 136/279 [07:10<07:29,  3.14s/it][ASV] Extracting eval:  49%|████▉     | 137/279 [07:13<07:26,  3.14s/it][ASV] Extracting eval:  49%|████▉     | 138/279 [07:16<07:22,  3.14s/it][ASV] Extracting eval:  50%|████▉     | 139/279 [07:20<07:19,  3.14s/it][ASV] Extracting eval:  50%|█████     | 140/279 [07:23<07:16,  3.14s/it][ASV] Extracting eval:  51%|█████     | 141/279 [07:26<07:13,  3.14s/it][ASV] Extracting eval:  51%|█████     | 142/279 [07:29<07:10,  3.14s/it][ASV] Extracting eval:  51%|█████▏    | 143/279 [07:32<07:07,  3.14s/it][ASV] Extracting eval:  52%|█████▏    | 144/279 [07:35<07:03,  3.14s/it][ASV] Extracting eval:  52%|█████▏    | 145/279 [07:38<07:00,  3.14s/it][ASV] Extracting eval:  52%|█████▏    | 146/279 [07:41<06:57,  3.14s/it][ASV] Extracting eval:  53%|█████▎    | 147/279 [07:45<06:54,  3.14s/it][ASV] Extracting eval:  53%|█████▎    | 148/279 [07:48<06:51,  3.14s/it][ASV] Extracting eval:  53%|█████▎    | 149/279 [07:51<06:48,  3.14s/it][ASV] Extracting eval:  54%|█████▍    | 150/279 [07:54<06:45,  3.14s/it][ASV] Extracting eval:  54%|█████▍    | 151/279 [07:57<06:41,  3.14s/it][ASV] Extracting eval:  54%|█████▍    | 152/279 [08:00<06:38,  3.14s/it][ASV] Extracting eval:  55%|█████▍    | 153/279 [08:03<06:35,  3.14s/it][ASV] Extracting eval:  55%|█████▌    | 154/279 [08:07<06:32,  3.14s/it][ASV] Extracting eval:  56%|█████▌    | 155/279 [08:10<06:29,  3.14s/it][ASV] Extracting eval:  56%|█████▌    | 156/279 [08:13<06:26,  3.14s/it][ASV] Extracting eval:  56%|█████▋    | 157/279 [08:16<06:22,  3.14s/it][ASV] Extracting eval:  57%|█████▋    | 158/279 [08:19<06:19,  3.14s/it][ASV] Extracting eval:  57%|█████▋    | 159/279 [08:22<06:16,  3.14s/it][ASV] Extracting eval:  57%|█████▋    | 160/279 [08:25<06:13,  3.14s/it][ASV] Extracting eval:  58%|█████▊    | 161/279 [08:29<06:10,  3.14s/it][ASV] Extracting eval:  58%|█████▊    | 162/279 [08:32<06:07,  3.14s/it][ASV] Extracting eval:  58%|█████▊    | 163/279 [08:35<06:04,  3.14s/it][ASV] Extracting eval:  59%|█████▉    | 164/279 [08:38<06:01,  3.14s/it][ASV] Extracting eval:  59%|█████▉    | 165/279 [08:41<05:57,  3.14s/it][ASV] Extracting eval:  59%|█████▉    | 166/279 [08:44<05:54,  3.14s/it][ASV] Extracting eval:  60%|█████▉    | 167/279 [08:47<05:51,  3.14s/it][ASV] Extracting eval:  60%|██████    | 168/279 [08:51<05:48,  3.14s/it][ASV] Extracting eval:  61%|██████    | 169/279 [08:54<05:45,  3.14s/it][ASV] Extracting eval:  61%|██████    | 170/279 [08:57<05:42,  3.14s/it][ASV] Extracting eval:  61%|██████▏   | 171/279 [09:00<05:39,  3.14s/it][ASV] Extracting eval:  62%|██████▏   | 172/279 [09:03<05:36,  3.14s/it][ASV] Extracting eval:  62%|██████▏   | 173/279 [09:06<05:32,  3.14s/it][ASV] Extracting eval:  62%|██████▏   | 174/279 [09:09<05:29,  3.14s/it][ASV] Extracting eval:  63%|██████▎   | 175/279 [09:13<05:26,  3.14s/it][ASV] Extracting eval:  63%|██████▎   | 176/279 [09:16<05:23,  3.14s/it][ASV] Extracting eval:  63%|██████▎   | 177/279 [09:19<05:20,  3.14s/it][ASV] Extracting eval:  64%|██████▍   | 178/279 [09:22<05:17,  3.14s/it][ASV] Extracting eval:  64%|██████▍   | 179/279 [09:25<05:13,  3.14s/it][ASV] Extracting eval:  65%|██████▍   | 180/279 [09:28<05:10,  3.14s/it][ASV] Extracting eval:  65%|██████▍   | 181/279 [09:31<05:07,  3.14s/it][ASV] Extracting eval:  65%|██████▌   | 182/279 [09:35<05:04,  3.14s/it][ASV] Extracting eval:  66%|██████▌   | 183/279 [09:38<05:01,  3.14s/it][ASV] Extracting eval:  66%|██████▌   | 184/279 [09:41<04:58,  3.14s/it][ASV] Extracting eval:  66%|██████▋   | 185/279 [09:44<04:55,  3.14s/it][ASV] Extracting eval:  67%|██████▋   | 186/279 [09:47<04:51,  3.14s/it][ASV] Extracting eval:  67%|██████▋   | 187/279 [09:50<04:48,  3.14s/it][ASV] Extracting eval:  67%|██████▋   | 188/279 [09:53<04:45,  3.14s/it][ASV] Extracting eval:  68%|██████▊   | 189/279 [09:57<04:42,  3.14s/it][ASV] Extracting eval:  68%|██████▊   | 190/279 [10:00<04:39,  3.14s/it][ASV] Extracting eval:  68%|██████▊   | 191/279 [10:03<04:36,  3.14s/it][ASV] Extracting eval:  69%|██████▉   | 192/279 [10:06<04:33,  3.14s/it][ASV] Extracting eval:  69%|██████▉   | 193/279 [10:09<04:30,  3.14s/it][ASV] Extracting eval:  70%|██████▉   | 194/279 [10:12<04:26,  3.14s/it][ASV] Extracting eval:  70%|██████▉   | 195/279 [10:15<04:23,  3.14s/it][ASV] Extracting eval:  70%|███████   | 196/279 [10:18<04:20,  3.14s/it][ASV] Extracting eval:  71%|███████   | 197/279 [10:22<04:17,  3.14s/it][ASV] Extracting eval:  71%|███████   | 198/279 [10:25<04:14,  3.14s/it][ASV] Extracting eval:  71%|███████▏  | 199/279 [10:28<04:11,  3.14s/it][ASV] Extracting eval:  72%|███████▏  | 200/279 [10:31<04:07,  3.14s/it][ASV] Extracting eval:  72%|███████▏  | 201/279 [10:34<04:04,  3.14s/it][ASV] Extracting eval:  72%|███████▏  | 202/279 [10:37<04:01,  3.14s/it][ASV] Extracting eval:  73%|███████▎  | 203/279 [10:40<03:58,  3.14s/it][ASV] Extracting eval:  73%|███████▎  | 204/279 [10:44<03:55,  3.14s/it][ASV] Extracting eval:  73%|███████▎  | 205/279 [10:47<03:52,  3.14s/it][ASV] Extracting eval:  74%|███████▍  | 206/279 [10:50<03:49,  3.14s/it][ASV] Extracting eval:  74%|███████▍  | 207/279 [10:53<03:46,  3.14s/it][ASV] Extracting eval:  75%|███████▍  | 208/279 [10:56<03:42,  3.14s/it][ASV] Extracting eval:  75%|███████▍  | 209/279 [10:59<03:39,  3.14s/it][ASV] Extracting eval:  75%|███████▌  | 210/279 [11:02<03:36,  3.14s/it][ASV] Extracting eval:  76%|███████▌  | 211/279 [11:06<03:33,  3.14s/it][ASV] Extracting eval:  76%|███████▌  | 212/279 [11:09<03:30,  3.14s/it][ASV] Extracting eval:  76%|███████▋  | 213/279 [11:12<03:27,  3.14s/it][ASV] Extracting eval:  77%|███████▋  | 214/279 [11:15<03:24,  3.14s/it][ASV] Extracting eval:  77%|███████▋  | 215/279 [11:18<03:20,  3.14s/it][ASV] Extracting eval:  77%|███████▋  | 216/279 [11:21<03:17,  3.14s/it][ASV] Extracting eval:  78%|███████▊  | 217/279 [11:24<03:14,  3.14s/it][ASV] Extracting eval:  78%|███████▊  | 218/279 [11:28<03:11,  3.14s/it][ASV] Extracting eval:  78%|███████▊  | 219/279 [11:31<03:08,  3.14s/it][ASV] Extracting eval:  79%|███████▉  | 220/279 [11:34<03:05,  3.14s/it][ASV] Extracting eval:  79%|███████▉  | 221/279 [11:37<03:02,  3.14s/it][ASV] Extracting eval:  80%|███████▉  | 222/279 [11:40<02:59,  3.14s/it][ASV] Extracting eval:  80%|███████▉  | 223/279 [11:43<02:55,  3.14s/it][ASV] Extracting eval:  80%|████████  | 224/279 [11:46<02:52,  3.14s/it][ASV] Extracting eval:  81%|████████  | 225/279 [11:50<02:49,  3.14s/it][ASV] Extracting eval:  81%|████████  | 226/279 [11:53<02:46,  3.14s/it][ASV] Extracting eval:  81%|████████▏ | 227/279 [11:56<02:43,  3.14s/it][ASV] Extracting eval:  82%|████████▏ | 228/279 [11:59<02:40,  3.14s/it][ASV] Extracting eval:  82%|████████▏ | 229/279 [12:02<02:37,  3.14s/it][ASV] Extracting eval:  82%|████████▏ | 230/279 [12:05<02:33,  3.14s/it][ASV] Extracting eval:  83%|████████▎ | 231/279 [12:08<02:30,  3.14s/it][ASV] Extracting eval:  83%|████████▎ | 232/279 [12:12<02:27,  3.14s/it][ASV] Extracting eval:  84%|████████▎ | 233/279 [12:15<02:24,  3.14s/it][ASV] Extracting eval:  84%|████████▍ | 234/279 [12:18<02:21,  3.14s/it][ASV] Extracting eval:  84%|████████▍ | 235/279 [12:21<02:18,  3.14s/it][ASV] Extracting eval:  85%|████████▍ | 236/279 [12:24<02:15,  3.14s/it][ASV] Extracting eval:  85%|████████▍ | 237/279 [12:27<02:11,  3.14s/it][ASV] Extracting eval:  85%|████████▌ | 238/279 [12:30<02:08,  3.14s/it][ASV] Extracting eval:  86%|████████▌ | 239/279 [12:34<02:05,  3.14s/it][ASV] Extracting eval:  86%|████████▌ | 240/279 [12:37<02:02,  3.14s/it][ASV] Extracting eval:  86%|████████▋ | 241/279 [12:40<01:59,  3.14s/it][ASV] Extracting eval:  87%|████████▋ | 242/279 [12:43<01:56,  3.14s/it][ASV] Extracting eval:  87%|████████▋ | 243/279 [12:46<01:53,  3.14s/it][ASV] Extracting eval:  87%|████████▋ | 244/279 [12:49<01:49,  3.14s/it][ASV] Extracting eval:  88%|████████▊ | 245/279 [12:52<01:46,  3.14s/it][ASV] Extracting eval:  88%|████████▊ | 246/279 [12:55<01:43,  3.14s/it][ASV] Extracting eval:  89%|████████▊ | 247/279 [12:59<01:40,  3.14s/it][ASV] Extracting eval:  89%|████████▉ | 248/279 [13:02<01:37,  3.14s/it][ASV] Extracting eval:  89%|████████▉ | 249/279 [13:05<01:34,  3.14s/it][ASV] Extracting eval:  90%|████████▉ | 250/279 [13:08<01:31,  3.14s/it][ASV] Extracting eval:  90%|████████▉ | 251/279 [13:11<01:27,  3.14s/it][ASV] Extracting eval:  90%|█████████ | 252/279 [13:14<01:24,  3.14s/it][ASV] Extracting eval:  91%|█████████ | 253/279 [13:17<01:21,  3.14s/it][ASV] Extracting eval:  91%|█████████ | 254/279 [13:21<01:18,  3.14s/it][ASV] Extracting eval:  91%|█████████▏| 255/279 [13:24<01:15,  3.14s/it][ASV] Extracting eval:  92%|█████████▏| 256/279 [13:27<01:12,  3.14s/it][ASV] Extracting eval:  92%|█████████▏| 257/279 [13:30<01:09,  3.14s/it][ASV] Extracting eval:  92%|█████████▏| 258/279 [13:33<01:05,  3.14s/it][ASV] Extracting eval:  93%|█████████▎| 259/279 [13:36<01:02,  3.14s/it][ASV] Extracting eval:  93%|█████████▎| 260/279 [13:39<00:59,  3.14s/it][ASV] Extracting eval:  94%|█████████▎| 261/279 [13:43<00:56,  3.14s/it][ASV] Extracting eval:  94%|█████████▍| 262/279 [13:46<00:53,  3.14s/it][ASV] Extracting eval:  94%|█████████▍| 263/279 [13:49<00:50,  3.14s/it][ASV] Extracting eval:  95%|█████████▍| 264/279 [13:52<00:47,  3.14s/it][ASV] Extracting eval:  95%|█████████▍| 265/279 [13:55<00:43,  3.14s/it][ASV] Extracting eval:  95%|█████████▌| 266/279 [13:58<00:40,  3.14s/it][ASV] Extracting eval:  96%|█████████▌| 267/279 [14:01<00:37,  3.14s/it][ASV] Extracting eval:  96%|█████████▌| 268/279 [14:05<00:34,  3.14s/it][ASV] Extracting eval:  96%|█████████▋| 269/279 [14:08<00:31,  3.14s/it][ASV] Extracting eval:  97%|█████████▋| 270/279 [14:11<00:28,  3.14s/it][ASV] Extracting eval:  97%|█████████▋| 271/279 [14:14<00:25,  3.14s/it][ASV] Extracting eval:  97%|█████████▋| 272/279 [14:17<00:21,  3.14s/it][ASV] Extracting eval:  98%|█████████▊| 273/279 [14:20<00:18,  3.14s/it][ASV] Extracting eval:  98%|█████████▊| 274/279 [14:23<00:15,  3.14s/it][ASV] Extracting eval:  99%|█████████▊| 275/279 [14:27<00:12,  3.14s/it][ASV] Extracting eval:  99%|█████████▉| 276/279 [14:30<00:09,  3.14s/it][ASV] Extracting eval:  99%|█████████▉| 277/279 [14:33<00:06,  3.14s/it][ASV] Extracting eval: 100%|█████████▉| 278/279 [14:36<00:03,  3.14s/it][ASV] Extracting eval: 100%|██████████| 279/279 [14:37<00:00,  2.46s/it][ASV] Extracting eval: 100%|██████████| 279/279 [14:37<00:00,  3.14s/it]
/home/jsudan/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[OK][ASV] Saved eval: embeddings (71237, 256), labels (71237,)
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/eval_embeddings.npy
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/eval_labels.npy
==> Building In-The-Wild dataset...
[ITW] Extracting:   0%|          | 0/125 [00:00<?, ?it/s][ITW] Extracting:   1%|          | 1/125 [00:06<12:45,  6.17s/it][ITW] Extracting:   2%|▏         | 2/125 [00:09<08:57,  4.37s/it][ITW] Extracting:   2%|▏         | 3/125 [00:12<07:43,  3.80s/it][ITW] Extracting:   3%|▎         | 4/125 [00:15<07:06,  3.53s/it][ITW] Extracting:   4%|▍         | 5/125 [00:18<06:45,  3.38s/it][ITW] Extracting:   5%|▍         | 6/125 [00:21<06:32,  3.30s/it][ITW] Extracting:   6%|▌         | 7/125 [00:24<06:22,  3.24s/it][ITW] Extracting:   6%|▋         | 8/125 [00:28<06:14,  3.20s/it][ITW] Extracting:   7%|▋         | 9/125 [00:31<06:09,  3.18s/it][ITW] Extracting:   8%|▊         | 10/125 [00:34<06:04,  3.17s/it][ITW] Extracting:   9%|▉         | 11/125 [00:37<05:59,  3.16s/it][ITW] Extracting:  10%|▉         | 12/125 [00:40<05:55,  3.15s/it][ITW] Extracting:  10%|█         | 13/125 [00:43<05:52,  3.15s/it][ITW] Extracting:  11%|█         | 14/125 [00:46<05:48,  3.14s/it][ITW] Extracting:  12%|█▏        | 15/125 [00:49<05:45,  3.14s/it][ITW] Extracting:  13%|█▎        | 16/125 [00:53<05:42,  3.14s/it][ITW] Extracting:  14%|█▎        | 17/125 [00:56<05:39,  3.14s/it][ITW] Extracting:  14%|█▍        | 18/125 [00:59<05:35,  3.14s/it][ITW] Extracting:  15%|█▌        | 19/125 [01:02<05:32,  3.14s/it][ITW] Extracting:  16%|█▌        | 20/125 [01:05<05:29,  3.14s/it][ITW] Extracting:  17%|█▋        | 21/125 [01:08<05:26,  3.14s/it][ITW] Extracting:  18%|█▊        | 22/125 [01:11<05:23,  3.14s/it][ITW] Extracting:  18%|█▊        | 23/125 [01:15<05:20,  3.14s/it][ITW] Extracting:  19%|█▉        | 24/125 [01:18<05:17,  3.14s/it][ITW] Extracting:  20%|██        | 25/125 [01:21<05:14,  3.14s/it][ITW] Extracting:  21%|██        | 26/125 [01:24<05:11,  3.14s/it][ITW] Extracting:  22%|██▏       | 27/125 [01:27<05:08,  3.14s/it][ITW] Extracting:  22%|██▏       | 28/125 [01:30<05:04,  3.14s/it][ITW] Extracting:  23%|██▎       | 29/125 [01:33<05:01,  3.14s/it][ITW] Extracting:  24%|██▍       | 30/125 [01:37<04:58,  3.14s/it][ITW] Extracting:  25%|██▍       | 31/125 [01:40<04:55,  3.14s/it][ITW] Extracting:  26%|██▌       | 32/125 [01:43<04:52,  3.14s/it][ITW] Extracting:  26%|██▋       | 33/125 [01:46<04:49,  3.14s/it][ITW] Extracting:  27%|██▋       | 34/125 [01:49<04:46,  3.14s/it][ITW] Extracting:  28%|██▊       | 35/125 [01:52<04:43,  3.14s/it][ITW] Extracting:  29%|██▉       | 36/125 [01:55<04:39,  3.15s/it][ITW] Extracting:  30%|██▉       | 37/125 [01:59<04:36,  3.15s/it][ITW] Extracting:  30%|███       | 38/125 [02:02<04:33,  3.15s/it][ITW] Extracting:  31%|███       | 39/125 [02:05<04:30,  3.15s/it][ITW] Extracting:  32%|███▏      | 40/125 [02:08<04:27,  3.15s/it][ITW] Extracting:  33%|███▎      | 41/125 [02:11<04:24,  3.14s/it][ITW] Extracting:  34%|███▎      | 42/125 [02:14<04:20,  3.14s/it][ITW] Extracting:  34%|███▍      | 43/125 [02:17<04:17,  3.15s/it][ITW] Extracting:  35%|███▌      | 44/125 [02:21<04:14,  3.14s/it][ITW] Extracting:  36%|███▌      | 45/125 [02:24<04:11,  3.14s/it][ITW] Extracting:  37%|███▋      | 46/125 [02:27<04:08,  3.14s/it][ITW] Extracting:  38%|███▊      | 47/125 [02:30<04:05,  3.14s/it][ITW] Extracting:  38%|███▊      | 48/125 [02:33<04:02,  3.14s/it][ITW] Extracting:  39%|███▉      | 49/125 [02:36<03:58,  3.14s/it][ITW] Extracting:  40%|████      | 50/125 [02:39<03:55,  3.14s/it][ITW] Extracting:  41%|████      | 51/125 [02:43<03:52,  3.14s/it][ITW] Extracting:  42%|████▏     | 52/125 [02:46<03:49,  3.14s/it][ITW] Extracting:  42%|████▏     | 53/125 [02:49<03:46,  3.14s/it][ITW] Extracting:  43%|████▎     | 54/125 [02:52<03:43,  3.14s/it][ITW] Extracting:  44%|████▍     | 55/125 [02:55<03:40,  3.14s/it][ITW] Extracting:  45%|████▍     | 56/125 [02:58<03:36,  3.14s/it][ITW] Extracting:  46%|████▌     | 57/125 [03:01<03:33,  3.14s/it][ITW] Extracting:  46%|████▋     | 58/125 [03:05<03:30,  3.14s/it][ITW] Extracting:  47%|████▋     | 59/125 [03:08<03:27,  3.15s/it][ITW] Extracting:  48%|████▊     | 60/125 [03:11<03:24,  3.14s/it][ITW] Extracting:  49%|████▉     | 61/125 [03:14<03:21,  3.14s/it][ITW] Extracting:  50%|████▉     | 62/125 [03:17<03:18,  3.14s/it][ITW] Extracting:  50%|█████     | 63/125 [03:20<03:14,  3.14s/it][ITW] Extracting:  51%|█████     | 64/125 [03:24<03:11,  3.14s/it][ITW] Extracting:  52%|█████▏    | 65/125 [03:27<03:08,  3.14s/it][ITW] Extracting:  53%|█████▎    | 66/125 [03:30<03:05,  3.14s/it][ITW] Extracting:  54%|█████▎    | 67/125 [03:33<03:02,  3.14s/it][ITW] Extracting:  54%|█████▍    | 68/125 [03:36<02:59,  3.14s/it][ITW] Extracting:  55%|█████▌    | 69/125 [03:39<02:56,  3.14s/it][ITW] Extracting:  56%|█████▌    | 70/125 [03:42<02:52,  3.14s/it][ITW] Extracting:  57%|█████▋    | 71/125 [03:46<02:49,  3.14s/it][ITW] Extracting:  58%|█████▊    | 72/125 [03:49<02:46,  3.14s/it][ITW] Extracting:  58%|█████▊    | 73/125 [03:52<02:43,  3.14s/it][ITW] Extracting:  59%|█████▉    | 74/125 [03:55<02:40,  3.14s/it][ITW] Extracting:  60%|██████    | 75/125 [03:58<02:37,  3.14s/it][ITW] Extracting:  61%|██████    | 76/125 [04:01<02:33,  3.14s/it][ITW] Extracting:  62%|██████▏   | 77/125 [04:04<02:30,  3.14s/it][ITW] Extracting:  62%|██████▏   | 78/125 [04:07<02:27,  3.14s/it][ITW] Extracting:  63%|██████▎   | 79/125 [04:11<02:24,  3.14s/it][ITW] Extracting:  64%|██████▍   | 80/125 [04:14<02:21,  3.14s/it][ITW] Extracting:  65%|██████▍   | 81/125 [04:17<02:18,  3.14s/it][ITW] Extracting:  66%|██████▌   | 82/125 [04:20<02:15,  3.14s/it][ITW] Extracting:  66%|██████▋   | 83/125 [04:23<02:12,  3.14s/it][ITW] Extracting:  67%|██████▋   | 84/125 [04:26<02:08,  3.14s/it][ITW] Extracting:  68%|██████▊   | 85/125 [04:30<02:05,  3.14s/it][ITW] Extracting:  69%|██████▉   | 86/125 [04:33<02:02,  3.14s/it][ITW] Extracting:  70%|██████▉   | 87/125 [04:36<01:59,  3.14s/it][ITW] Extracting:  70%|███████   | 88/125 [04:39<01:56,  3.14s/it][ITW] Extracting:  71%|███████   | 89/125 [04:42<01:53,  3.14s/it][ITW] Extracting:  72%|███████▏  | 90/125 [04:45<01:50,  3.14s/it][ITW] Extracting:  73%|███████▎  | 91/125 [04:48<01:46,  3.14s/it][ITW] Extracting:  74%|███████▎  | 92/125 [04:52<01:43,  3.14s/it][ITW] Extracting:  74%|███████▍  | 93/125 [04:55<01:40,  3.14s/it][ITW] Extracting:  75%|███████▌  | 94/125 [04:58<01:37,  3.14s/it][ITW] Extracting:  76%|███████▌  | 95/125 [05:01<01:34,  3.14s/it][ITW] Extracting:  77%|███████▋  | 96/125 [05:04<01:31,  3.14s/it][ITW] Extracting:  78%|███████▊  | 97/125 [05:07<01:28,  3.14s/it][ITW] Extracting:  78%|███████▊  | 98/125 [05:10<01:24,  3.14s/it][ITW] Extracting:  79%|███████▉  | 99/125 [05:14<01:21,  3.14s/it][ITW] Extracting:  80%|████████  | 100/125 [05:17<01:18,  3.14s/it][ITW] Extracting:  81%|████████  | 101/125 [05:20<01:15,  3.14s/it][ITW] Extracting:  82%|████████▏ | 102/125 [05:23<01:12,  3.14s/it][ITW] Extracting:  82%|████████▏ | 103/125 [05:26<01:09,  3.14s/it][ITW] Extracting:  83%|████████▎ | 104/125 [05:29<01:06,  3.14s/it][ITW] Extracting:  84%|████████▍ | 105/125 [05:32<01:02,  3.14s/it][ITW] Extracting:  85%|████████▍ | 106/125 [05:36<00:59,  3.14s/it][ITW] Extracting:  86%|████████▌ | 107/125 [05:39<00:56,  3.14s/it][ITW] Extracting:  86%|████████▋ | 108/125 [05:42<00:53,  3.14s/it][ITW] Extracting:  87%|████████▋ | 109/125 [05:45<00:50,  3.14s/it][ITW] Extracting:  88%|████████▊ | 110/125 [05:48<00:47,  3.14s/it][ITW] Extracting:  89%|████████▉ | 111/125 [05:51<00:44,  3.14s/it][ITW] Extracting:  90%|████████▉ | 112/125 [05:54<00:40,  3.14s/it][ITW] Extracting:  90%|█████████ | 113/125 [05:58<00:37,  3.14s/it][ITW] Extracting:  91%|█████████ | 114/125 [06:01<00:34,  3.15s/it][ITW] Extracting:  92%|█████████▏| 115/125 [06:04<00:31,  3.14s/it][ITW] Extracting:  93%|█████████▎| 116/125 [06:07<00:28,  3.14s/it][ITW] Extracting:  94%|█████████▎| 117/125 [06:10<00:25,  3.14s/it][ITW] Extracting:  94%|█████████▍| 118/125 [06:13<00:22,  3.14s/it][ITW] Extracting:  95%|█████████▌| 119/125 [06:16<00:18,  3.14s/it][ITW] Extracting:  96%|█████████▌| 120/125 [06:20<00:15,  3.14s/it][ITW] Extracting:  97%|█████████▋| 121/125 [06:23<00:12,  3.14s/it][ITW] Extracting:  98%|█████████▊| 122/125 [06:26<00:09,  3.14s/it][ITW] Extracting:  98%|█████████▊| 123/125 [06:29<00:06,  3.14s/it][ITW] Extracting:  99%|█████████▉| 124/125 [06:32<00:03,  3.14s/it][ITW] Extracting: 100%|██████████| 125/125 [06:33<00:00,  2.34s/it][ITW] Extracting: 100%|██████████| 125/125 [06:33<00:00,  3.15s/it]
[OK][ITW] Saved ITW embeddings: (31779, 256), labels (31779,)
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ITW/supcon_uniformity_weight_0.1/itw_embeddings.npy
     -> /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ITW/supcon_uniformity_weight_0.1/itw_labels.npy
Using device: cuda
Train embeddings: (25380, 256), Dev embeddings: (24844, 256)
Class balance: pos_weight=8.837
[epoch 001 | step 0010] train_loss=1.1320
[epoch 001 | step 0020] train_loss=1.4690
[epoch 001 | step 0030] train_loss=1.5384
[epoch 001 | step 0040] train_loss=1.0296
[epoch 001 | step 0050] train_loss=1.4489
[epoch 001 | step 0060] train_loss=0.8552
[epoch 001 | step 0070] train_loss=1.0975
[epoch 001 | step 0080] train_loss=1.0941
[epoch 001 | step 0090] train_loss=1.0844
[epoch 001 | step 0100] train_loss=1.0005
[epoch 001 | step 0110] train_loss=0.9182
[epoch 001 | step 0120] train_loss=1.1475
[epoch 001 | step 0130] train_loss=1.1440
[epoch 001 | step 0140] train_loss=1.3009
[epoch 001 | step 0150] train_loss=1.0561
[epoch 001 | step 0160] train_loss=1.2079
[epoch 001 | step 0170] train_loss=0.9660
[epoch 001 | step 0180] train_loss=1.1966
[epoch 001 | step 0190] train_loss=0.9525
[epoch 001 | step 0200] train_loss=1.0314
[epoch 001 | step 0210] train_loss=1.0216
[epoch 001 | step 0220] train_loss=1.1729
[epoch 001 | step 0230] train_loss=1.0883
[epoch 001 | step 0240] train_loss=1.0801
[epoch 001 | step 0250] train_loss=1.1475
[epoch 001 | step 0260] train_loss=1.0714
[epoch 001 | step 0270] train_loss=1.2866
[epoch 001 | step 0280] train_loss=1.1347
[epoch 001 | step 0290] train_loss=0.9091
[epoch 001 | step 0300] train_loss=1.1888
[epoch 001 | step 0310] train_loss=0.9659
[epoch 001 | step 0320] train_loss=1.0331
[epoch 001 | step 0330] train_loss=0.9554
[epoch 001 | step 0340] train_loss=1.0259
[epoch 001 | step 0350] train_loss=1.3676
[epoch 001 | step 0360] train_loss=1.0143
[epoch 001 | step 0370] train_loss=0.8762
[epoch 001 | step 0380] train_loss=1.2721
[epoch 001 | step 0390] train_loss=1.3395
[epoch 001] train_loss=1.1449 | dev_loss=1.0383 | dev_acc=99.99% | dev_auc=1.0000 | dev_eer=0.07%
[epoch 001] ✓ New best EER=0.07% -> checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
[epoch 002 | step 0010] train_loss=1.3338
[epoch 002 | step 0020] train_loss=0.9821
[epoch 002 | step 0030] train_loss=1.2526
[epoch 002 | step 0040] train_loss=1.1102
[epoch 002 | step 0050] train_loss=0.9597
[epoch 002 | step 0060] train_loss=0.9670
[epoch 002 | step 0070] train_loss=0.9685
[epoch 002 | step 0080] train_loss=1.1623
[epoch 002 | step 0090] train_loss=1.0208
[epoch 002 | step 0100] train_loss=0.8741
[epoch 002 | step 0110] train_loss=0.7490
[epoch 002 | step 0120] train_loss=0.9936
[epoch 002 | step 0130] train_loss=0.8040
[epoch 002 | step 0140] train_loss=0.8647
[epoch 002 | step 0150] train_loss=0.9162
[epoch 002 | step 0160] train_loss=0.8678
[epoch 002 | step 0170] train_loss=0.7915
[epoch 002 | step 0180] train_loss=0.7231
[epoch 002 | step 0190] train_loss=1.0233
[epoch 002 | step 0200] train_loss=1.0184
[epoch 002 | step 0210] train_loss=1.0075
[epoch 002 | step 0220] train_loss=1.0776
[epoch 002 | step 0230] train_loss=1.1751
[epoch 002 | step 0240] train_loss=1.0655
[epoch 002 | step 0250] train_loss=0.6377
[epoch 002 | step 0260] train_loss=0.6843
[epoch 002 | step 0270] train_loss=1.0550
[epoch 002 | step 0280] train_loss=0.7474
[epoch 002 | step 0290] train_loss=0.6266
[epoch 002 | step 0300] train_loss=0.8526
[epoch 002 | step 0310] train_loss=0.7941
[epoch 002 | step 0320] train_loss=1.0111
[epoch 002 | step 0330] train_loss=0.7937
[epoch 002 | step 0340] train_loss=1.0571
[epoch 002 | step 0350] train_loss=0.7734
[epoch 002 | step 0360] train_loss=0.8249
[epoch 002 | step 0370] train_loss=0.8249
[epoch 002 | step 0380] train_loss=0.7084
[epoch 002 | step 0390] train_loss=0.8725
[epoch 002] train_loss=0.9309 | dev_loss=0.8508 | dev_acc=99.99% | dev_auc=1.0000 | dev_eer=0.04%
[epoch 002] ✓ New best EER=0.04% -> checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
[epoch 003 | step 0010] train_loss=0.8640
[epoch 003 | step 0020] train_loss=0.7950
[epoch 003 | step 0030] train_loss=0.6810
[epoch 003 | step 0040] train_loss=0.8030
[epoch 003 | step 0050] train_loss=0.6946
[epoch 003 | step 0060] train_loss=0.7298
[epoch 003 | step 0070] train_loss=0.7263
[epoch 003 | step 0080] train_loss=0.7846
[epoch 003 | step 0090] train_loss=0.8339
[epoch 003 | step 0100] train_loss=0.8199
[epoch 003 | step 0110] train_loss=0.8209
[epoch 003 | step 0120] train_loss=0.8110
[epoch 003 | step 0130] train_loss=0.6507
[epoch 003 | step 0140] train_loss=0.5485
[epoch 003 | step 0150] train_loss=0.8067
[epoch 003 | step 0160] train_loss=0.5471
[epoch 003 | step 0170] train_loss=0.6894
[epoch 003 | step 0180] train_loss=0.7059
[epoch 003 | step 0190] train_loss=0.7431
[epoch 003 | step 0200] train_loss=0.6312
[epoch 003 | step 0210] train_loss=0.7807
[epoch 003 | step 0220] train_loss=0.6298
[epoch 003 | step 0230] train_loss=0.6757
[epoch 003 | step 0240] train_loss=0.8183
[epoch 003 | step 0250] train_loss=0.8226
[epoch 003 | step 0260] train_loss=0.7048
[epoch 003 | step 0270] train_loss=0.6428
[epoch 003 | step 0280] train_loss=0.6582
[epoch 003 | step 0290] train_loss=0.9084
[epoch 003 | step 0300] train_loss=0.7351
[epoch 003 | step 0310] train_loss=0.6486
[epoch 003 | step 0320] train_loss=0.7832
[epoch 003 | step 0330] train_loss=1.1436
[epoch 003 | step 0340] train_loss=0.5880
[epoch 003 | step 0350] train_loss=0.8776
[epoch 003 | step 0360] train_loss=0.7748
[epoch 003 | step 0370] train_loss=0.8543
[epoch 003 | step 0380] train_loss=0.7110
[epoch 003 | step 0390] train_loss=0.8779
[epoch 003] train_loss=0.7609 | dev_loss=0.7016 | dev_acc=99.99% | dev_auc=1.0000 | dev_eer=0.03%
[epoch 003] ✓ New best EER=0.03% -> checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
[epoch 004 | step 0010] train_loss=0.7862
[epoch 004 | step 0020] train_loss=0.7668
[epoch 004 | step 0030] train_loss=0.4813
[epoch 004 | step 0040] train_loss=0.7376
[epoch 004 | step 0050] train_loss=0.7871
[epoch 004 | step 0060] train_loss=0.6983
[epoch 004 | step 0070] train_loss=0.7491
[epoch 004 | step 0080] train_loss=0.5544
[epoch 004 | step 0090] train_loss=0.5074
[epoch 004 | step 0100] train_loss=0.6395
[epoch 004 | step 0110] train_loss=0.7636
[epoch 004 | step 0120] train_loss=0.7444
[epoch 004 | step 0130] train_loss=0.6617
[epoch 004 | step 0140] train_loss=0.6961
[epoch 004 | step 0150] train_loss=0.7054
[epoch 004 | step 0160] train_loss=0.4870
[epoch 004 | step 0170] train_loss=0.6113
[epoch 004 | step 0180] train_loss=0.5722
[epoch 004 | step 0190] train_loss=0.5523
[epoch 004 | step 0200] train_loss=0.5619
[epoch 004 | step 0210] train_loss=0.6059
[epoch 004 | step 0220] train_loss=0.5536
[epoch 004 | step 0230] train_loss=0.6460
[epoch 004 | step 0240] train_loss=0.4351
[epoch 004 | step 0250] train_loss=0.5128
[epoch 004 | step 0260] train_loss=0.5941
[epoch 004 | step 0270] train_loss=0.7842
[epoch 004 | step 0280] train_loss=0.7507
[epoch 004 | step 0290] train_loss=0.7031
[epoch 004 | step 0300] train_loss=0.6098
[epoch 004 | step 0310] train_loss=0.5247
[epoch 004 | step 0320] train_loss=0.5301
[epoch 004 | step 0330] train_loss=0.5918
[epoch 004 | step 0340] train_loss=0.7237
[epoch 004 | step 0350] train_loss=0.4906
[epoch 004 | step 0360] train_loss=0.6062
[epoch 004 | step 0370] train_loss=0.5031
[epoch 004 | step 0380] train_loss=0.6340
[epoch 004 | step 0390] train_loss=0.5412
[epoch 004] train_loss=0.6258 | dev_loss=0.5825 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.03%
[epoch 004] ✓ New best EER=0.03% -> checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
[epoch 005 | step 0010] train_loss=0.4112
[epoch 005 | step 0020] train_loss=0.6036
[epoch 005 | step 0030] train_loss=0.5326
[epoch 005 | step 0040] train_loss=0.7103
[epoch 005 | step 0050] train_loss=0.5284
[epoch 005 | step 0060] train_loss=0.4916
[epoch 005 | step 0070] train_loss=0.6041
[epoch 005 | step 0080] train_loss=0.6200
[epoch 005 | step 0090] train_loss=0.5536
[epoch 005 | step 0100] train_loss=0.5597
[epoch 005 | step 0110] train_loss=0.7130
[epoch 005 | step 0120] train_loss=0.4875
[epoch 005 | step 0130] train_loss=0.4814
[epoch 005 | step 0140] train_loss=0.5500
[epoch 005 | step 0150] train_loss=0.5315
[epoch 005 | step 0160] train_loss=0.6605
[epoch 005 | step 0170] train_loss=0.5454
[epoch 005 | step 0180] train_loss=0.4022
[epoch 005 | step 0190] train_loss=0.5694
[epoch 005 | step 0200] train_loss=0.5503
[epoch 005 | step 0210] train_loss=0.5433
[epoch 005 | step 0220] train_loss=0.5767
[epoch 005 | step 0230] train_loss=0.5287
[epoch 005 | step 0240] train_loss=0.3663
[epoch 005 | step 0250] train_loss=0.5543
[epoch 005 | step 0260] train_loss=0.5142
[epoch 005 | step 0270] train_loss=0.6407
[epoch 005 | step 0280] train_loss=0.5272
[epoch 005 | step 0290] train_loss=0.5570
[epoch 005 | step 0300] train_loss=0.6776
[epoch 005 | step 0310] train_loss=0.5578
[epoch 005 | step 0320] train_loss=0.5317
[epoch 005 | step 0330] train_loss=0.4773
[epoch 005 | step 0340] train_loss=0.4622
[epoch 005 | step 0350] train_loss=0.4884
[epoch 005 | step 0360] train_loss=0.4751
[epoch 005 | step 0370] train_loss=0.4867
[epoch 005 | step 0380] train_loss=0.4380
[epoch 005 | step 0390] train_loss=0.3565
[epoch 005] train_loss=0.5182 | dev_loss=0.4868 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 005] ✓ New best EER=0.02% -> checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
[epoch 006 | step 0010] train_loss=0.4318
[epoch 006 | step 0020] train_loss=0.4434
[epoch 006 | step 0030] train_loss=0.5003
[epoch 006 | step 0040] train_loss=0.5725
[epoch 006 | step 0050] train_loss=0.6152
[epoch 006 | step 0060] train_loss=0.3349
[epoch 006 | step 0070] train_loss=0.4186
[epoch 006 | step 0080] train_loss=0.4429
[epoch 006 | step 0090] train_loss=0.4158
[epoch 006 | step 0100] train_loss=0.3930
[epoch 006 | step 0110] train_loss=0.4524
[epoch 006 | step 0120] train_loss=0.4266
[epoch 006 | step 0130] train_loss=0.4714
[epoch 006 | step 0140] train_loss=0.4217
[epoch 006 | step 0150] train_loss=0.4459
[epoch 006 | step 0160] train_loss=0.4668
[epoch 006 | step 0170] train_loss=0.5420
[epoch 006 | step 0180] train_loss=0.4197
[epoch 006 | step 0190] train_loss=0.3567
[epoch 006 | step 0200] train_loss=0.4415
[epoch 006 | step 0210] train_loss=0.4635
[epoch 006 | step 0220] train_loss=0.4027
[epoch 006 | step 0230] train_loss=0.4638
[epoch 006 | step 0240] train_loss=0.4064
[epoch 006 | step 0250] train_loss=0.4980
[epoch 006 | step 0260] train_loss=0.4102
[epoch 006 | step 0270] train_loss=0.5110
[epoch 006 | step 0280] train_loss=0.6065
[epoch 006 | step 0290] train_loss=0.3458
[epoch 006 | step 0300] train_loss=0.3662
[epoch 006 | step 0310] train_loss=0.5588
[epoch 006 | step 0320] train_loss=0.4263
[epoch 006 | step 0330] train_loss=0.4571
[epoch 006 | step 0340] train_loss=0.4398
[epoch 006 | step 0350] train_loss=0.3376
[epoch 006 | step 0360] train_loss=0.4098
[epoch 006 | step 0370] train_loss=0.3406
[epoch 006 | step 0380] train_loss=0.3120
[epoch 006 | step 0390] train_loss=0.3794
[epoch 006] train_loss=0.4319 | dev_loss=0.4094 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 006] No EER improvement for 1 epoch(s) (best=0.02%)
[epoch 007 | step 0010] train_loss=0.3424
[epoch 007 | step 0020] train_loss=0.3606
[epoch 007 | step 0030] train_loss=0.4854
[epoch 007 | step 0040] train_loss=0.4707
[epoch 007 | step 0050] train_loss=0.3448
[epoch 007 | step 0060] train_loss=0.3765
[epoch 007 | step 0070] train_loss=0.3777
[epoch 007 | step 0080] train_loss=0.5495
[epoch 007 | step 0090] train_loss=0.4072
[epoch 007 | step 0100] train_loss=0.3317
[epoch 007 | step 0110] train_loss=0.4198
[epoch 007 | step 0120] train_loss=0.3854
[epoch 007 | step 0130] train_loss=0.3417
[epoch 007 | step 0140] train_loss=0.3215
[epoch 007 | step 0150] train_loss=0.3408
[epoch 007 | step 0160] train_loss=0.3432
[epoch 007 | step 0170] train_loss=0.2629
[epoch 007 | step 0180] train_loss=0.5191
[epoch 007 | step 0190] train_loss=0.3061
[epoch 007 | step 0200] train_loss=0.4005
[epoch 007 | step 0210] train_loss=0.2707
[epoch 007 | step 0220] train_loss=0.4023
[epoch 007 | step 0230] train_loss=0.4286
[epoch 007 | step 0240] train_loss=0.3893
[epoch 007 | step 0250] train_loss=0.2447
[epoch 007 | step 0260] train_loss=0.4235
[epoch 007 | step 0270] train_loss=0.4266
[epoch 007 | step 0280] train_loss=0.2508
[epoch 007 | step 0290] train_loss=0.2429
[epoch 007 | step 0300] train_loss=0.2969
[epoch 007 | step 0310] train_loss=0.2819
[epoch 007 | step 0320] train_loss=0.3821
[epoch 007 | step 0330] train_loss=0.3296
[epoch 007 | step 0340] train_loss=0.4298
[epoch 007 | step 0350] train_loss=0.3502
[epoch 007 | step 0360] train_loss=0.3913
[epoch 007 | step 0370] train_loss=0.3031
[epoch 007 | step 0380] train_loss=0.3928
[epoch 007 | step 0390] train_loss=0.3278
[epoch 007] train_loss=0.3619 | dev_loss=0.3464 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 007] No EER improvement for 2 epoch(s) (best=0.02%)
[epoch 008 | step 0010] train_loss=0.3044
[epoch 008 | step 0020] train_loss=0.3902
[epoch 008 | step 0030] train_loss=0.4326
[epoch 008 | step 0040] train_loss=0.3760
[epoch 008 | step 0050] train_loss=0.3633
[epoch 008 | step 0060] train_loss=0.2907
[epoch 008 | step 0070] train_loss=0.3562
[epoch 008 | step 0080] train_loss=0.3429
[epoch 008 | step 0090] train_loss=0.3094
[epoch 008 | step 0100] train_loss=0.3078
[epoch 008 | step 0110] train_loss=0.2843
[epoch 008 | step 0120] train_loss=0.2583
[epoch 008 | step 0130] train_loss=0.3442
[epoch 008 | step 0140] train_loss=0.2026
[epoch 008 | step 0150] train_loss=0.3000
[epoch 008 | step 0160] train_loss=0.2712
[epoch 008 | step 0170] train_loss=0.3002
[epoch 008 | step 0180] train_loss=0.3490
[epoch 008 | step 0190] train_loss=0.3458
[epoch 008 | step 0200] train_loss=0.3064
[epoch 008 | step 0210] train_loss=0.3093
[epoch 008 | step 0220] train_loss=0.2385
[epoch 008 | step 0230] train_loss=0.2506
[epoch 008 | step 0240] train_loss=0.2650
[epoch 008 | step 0250] train_loss=0.2711
[epoch 008 | step 0260] train_loss=0.3167
[epoch 008 | step 0270] train_loss=0.2737
[epoch 008 | step 0280] train_loss=0.2715
[epoch 008 | step 0290] train_loss=0.3273
[epoch 008 | step 0300] train_loss=0.3722
[epoch 008 | step 0310] train_loss=0.3110
[epoch 008 | step 0320] train_loss=0.2840
[epoch 008 | step 0330] train_loss=0.2753
[epoch 008 | step 0340] train_loss=0.2962
[epoch 008 | step 0350] train_loss=0.3401
[epoch 008 | step 0360] train_loss=0.3040
[epoch 008 | step 0370] train_loss=0.2644
[epoch 008 | step 0380] train_loss=0.2638
[epoch 008 | step 0390] train_loss=0.2842
[epoch 008] train_loss=0.3049 | dev_loss=0.2944 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 008] No EER improvement for 3 epoch(s) (best=0.02%)
[epoch 009 | step 0010] train_loss=0.2539
[epoch 009 | step 0020] train_loss=0.2062
[epoch 009 | step 0030] train_loss=0.2313
[epoch 009 | step 0040] train_loss=0.3369
[epoch 009 | step 0050] train_loss=0.1793
[epoch 009 | step 0060] train_loss=0.2136
[epoch 009 | step 0070] train_loss=0.2645
[epoch 009 | step 0080] train_loss=0.3236
[epoch 009 | step 0090] train_loss=0.1959
[epoch 009 | step 0100] train_loss=0.2873
[epoch 009 | step 0110] train_loss=0.2084
[epoch 009 | step 0120] train_loss=0.2680
[epoch 009 | step 0130] train_loss=0.1994
[epoch 009 | step 0140] train_loss=0.3105
[epoch 009 | step 0150] train_loss=0.2542
[epoch 009 | step 0160] train_loss=0.3281
[epoch 009 | step 0170] train_loss=0.2945
[epoch 009 | step 0180] train_loss=0.2688
[epoch 009 | step 0190] train_loss=0.2092
[epoch 009 | step 0200] train_loss=0.2322
[epoch 009 | step 0210] train_loss=0.2874
[epoch 009 | step 0220] train_loss=0.1964
[epoch 009 | step 0230] train_loss=0.2426
[epoch 009 | step 0240] train_loss=0.2286
[epoch 009 | step 0250] train_loss=0.2926
[epoch 009 | step 0260] train_loss=0.2637
[epoch 009 | step 0270] train_loss=0.2289
[epoch 009 | step 0280] train_loss=0.2932
[epoch 009 | step 0290] train_loss=0.2950
[epoch 009 | step 0300] train_loss=0.2666
[epoch 009 | step 0310] train_loss=0.2233
[epoch 009 | step 0320] train_loss=0.2673
[epoch 009 | step 0330] train_loss=0.2580
[epoch 009 | step 0340] train_loss=0.2843
[epoch 009 | step 0350] train_loss=0.2452
[epoch 009 | step 0360] train_loss=0.2462
[epoch 009 | step 0370] train_loss=0.2093
[epoch 009 | step 0380] train_loss=0.2400
[epoch 009 | step 0390] train_loss=0.1533
[epoch 009] train_loss=0.2580 | dev_loss=0.2513 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 009] No EER improvement for 4 epoch(s) (best=0.02%)
[epoch 010 | step 0010] train_loss=0.2038
[epoch 010 | step 0020] train_loss=0.2300
[epoch 010 | step 0030] train_loss=0.2512
[epoch 010 | step 0040] train_loss=0.2267
[epoch 010 | step 0050] train_loss=0.2452
[epoch 010 | step 0060] train_loss=0.1874
[epoch 010 | step 0070] train_loss=0.2077
[epoch 010 | step 0080] train_loss=0.2454
[epoch 010 | step 0090] train_loss=0.2414
[epoch 010 | step 0100] train_loss=0.2685
[epoch 010 | step 0110] train_loss=0.2134
[epoch 010 | step 0120] train_loss=0.2010
[epoch 010 | step 0130] train_loss=0.2368
[epoch 010 | step 0140] train_loss=0.1787
[epoch 010 | step 0150] train_loss=0.2668
[epoch 010 | step 0160] train_loss=0.2639
[epoch 010 | step 0170] train_loss=0.2511
[epoch 010 | step 0180] train_loss=0.1789
[epoch 010 | step 0190] train_loss=0.2362
[epoch 010 | step 0200] train_loss=0.1974
[epoch 010 | step 0210] train_loss=0.2081
[epoch 010 | step 0220] train_loss=0.2448
[epoch 010 | step 0230] train_loss=0.2272
[epoch 010 | step 0240] train_loss=0.1938
[epoch 010 | step 0250] train_loss=0.2533
[epoch 010 | step 0260] train_loss=0.2307
[epoch 010 | step 0270] train_loss=0.2197
[epoch 010 | step 0280] train_loss=0.2435
[epoch 010 | step 0290] train_loss=0.2143
[epoch 010 | step 0300] train_loss=0.1738
[epoch 010 | step 0310] train_loss=0.2166
[epoch 010 | step 0320] train_loss=0.2085
[epoch 010 | step 0330] train_loss=0.1956
[epoch 010 | step 0340] train_loss=0.2370
[epoch 010 | step 0350] train_loss=0.1703
[epoch 010 | step 0360] train_loss=0.1674
[epoch 010 | step 0370] train_loss=0.2089
[epoch 010 | step 0380] train_loss=0.2355
[epoch 010 | step 0390] train_loss=0.2143
[epoch 010] train_loss=0.2191 | dev_loss=0.2154 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 010] ✓ New best EER=0.02% -> checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
[epoch 011 | step 0010] train_loss=0.2134
[epoch 011 | step 0020] train_loss=0.1855
[epoch 011 | step 0030] train_loss=0.1928
[epoch 011 | step 0040] train_loss=0.2080
[epoch 011 | step 0050] train_loss=0.1686
[epoch 011 | step 0060] train_loss=0.2363
[epoch 011 | step 0070] train_loss=0.2353
[epoch 011 | step 0080] train_loss=0.2348
[epoch 011 | step 0090] train_loss=0.1705
[epoch 011 | step 0100] train_loss=0.1636
[epoch 011 | step 0110] train_loss=0.2394
[epoch 011 | step 0120] train_loss=0.1757
[epoch 011 | step 0130] train_loss=0.1495
[epoch 011 | step 0140] train_loss=0.1788
[epoch 011 | step 0150] train_loss=0.1939
[epoch 011 | step 0160] train_loss=0.1735
[epoch 011 | step 0170] train_loss=0.1898
[epoch 011 | step 0180] train_loss=0.2075
[epoch 011 | step 0190] train_loss=0.1702
[epoch 011 | step 0200] train_loss=0.2164
[epoch 011 | step 0210] train_loss=0.1920
[epoch 011 | step 0220] train_loss=0.2865
[epoch 011 | step 0230] train_loss=0.1798
[epoch 011 | step 0240] train_loss=0.2256
[epoch 011 | step 0250] train_loss=0.1621
[epoch 011 | step 0260] train_loss=0.1642
[epoch 011 | step 0270] train_loss=0.2091
[epoch 011 | step 0280] train_loss=0.1383
[epoch 011 | step 0290] train_loss=0.1575
[epoch 011 | step 0300] train_loss=0.2345
[epoch 011 | step 0310] train_loss=0.1902
[epoch 011 | step 0320] train_loss=0.1691
[epoch 011 | step 0330] train_loss=0.1418
[epoch 011 | step 0340] train_loss=0.1798
[epoch 011 | step 0350] train_loss=0.1259
[epoch 011 | step 0360] train_loss=0.1600
[epoch 011 | step 0370] train_loss=0.1539
[epoch 011 | step 0380] train_loss=0.1764
[epoch 011 | step 0390] train_loss=0.1711
[epoch 011] train_loss=0.1868 | dev_loss=0.1852 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 011] No EER improvement for 1 epoch(s) (best=0.02%)
[epoch 012 | step 0010] train_loss=0.1869
[epoch 012 | step 0020] train_loss=0.1291
[epoch 012 | step 0030] train_loss=0.1465
[epoch 012 | step 0040] train_loss=0.1565
[epoch 012 | step 0050] train_loss=0.1511
[epoch 012 | step 0060] train_loss=0.1367
[epoch 012 | step 0070] train_loss=0.1478
[epoch 012 | step 0080] train_loss=0.1278
[epoch 012 | step 0090] train_loss=0.1674
[epoch 012 | step 0100] train_loss=0.1557
[epoch 012 | step 0110] train_loss=0.1242
[epoch 012 | step 0120] train_loss=0.2000
[epoch 012 | step 0130] train_loss=0.1112
[epoch 012 | step 0140] train_loss=0.1933
[epoch 012 | step 0150] train_loss=0.1525
[epoch 012 | step 0160] train_loss=0.1760
[epoch 012 | step 0170] train_loss=0.1338
[epoch 012 | step 0180] train_loss=0.1350
[epoch 012 | step 0190] train_loss=0.1194
[epoch 012 | step 0200] train_loss=0.1557
[epoch 012 | step 0210] train_loss=0.1359
[epoch 012 | step 0220] train_loss=0.1770
[epoch 012 | step 0230] train_loss=0.1024
[epoch 012 | step 0240] train_loss=0.1439
[epoch 012 | step 0250] train_loss=0.1885
[epoch 012 | step 0260] train_loss=0.1710
[epoch 012 | step 0270] train_loss=0.1546
[epoch 012 | step 0280] train_loss=0.1780
[epoch 012 | step 0290] train_loss=0.1313
[epoch 012 | step 0300] train_loss=0.1909
[epoch 012 | step 0310] train_loss=0.1294
[epoch 012 | step 0320] train_loss=0.1503
[epoch 012 | step 0330] train_loss=0.1250
[epoch 012 | step 0340] train_loss=0.1713
[epoch 012 | step 0350] train_loss=0.1558
[epoch 012 | step 0360] train_loss=0.1375
[epoch 012 | step 0370] train_loss=0.1430
[epoch 012 | step 0380] train_loss=0.1559
[epoch 012 | step 0390] train_loss=0.1542
[epoch 012] train_loss=0.1596 | dev_loss=0.1597 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 012] No EER improvement for 2 epoch(s) (best=0.02%)
[epoch 013 | step 0010] train_loss=0.1526
[epoch 013 | step 0020] train_loss=0.1559
[epoch 013 | step 0030] train_loss=0.1125
[epoch 013 | step 0040] train_loss=0.1693
[epoch 013 | step 0050] train_loss=0.1286
[epoch 013 | step 0060] train_loss=0.1179
[epoch 013 | step 0070] train_loss=0.2034
[epoch 013 | step 0080] train_loss=0.1578
[epoch 013 | step 0090] train_loss=0.1707
[epoch 013 | step 0100] train_loss=0.1154
[epoch 013 | step 0110] train_loss=0.1575
[epoch 013 | step 0120] train_loss=0.1301
[epoch 013 | step 0130] train_loss=0.1526
[epoch 013 | step 0140] train_loss=0.1216
[epoch 013 | step 0150] train_loss=0.1384
[epoch 013 | step 0160] train_loss=0.1197
[epoch 013 | step 0170] train_loss=0.1717
[epoch 013 | step 0180] train_loss=0.1412
[epoch 013 | step 0190] train_loss=0.1602
[epoch 013 | step 0200] train_loss=0.1465
[epoch 013 | step 0210] train_loss=0.1250
[epoch 013 | step 0220] train_loss=0.1289
[epoch 013 | step 0230] train_loss=0.1152
[epoch 013 | step 0240] train_loss=0.1445
[epoch 013 | step 0250] train_loss=0.1272
[epoch 013 | step 0260] train_loss=0.1217
[epoch 013 | step 0270] train_loss=0.0993
[epoch 013 | step 0280] train_loss=0.1338
[epoch 013 | step 0290] train_loss=0.1342
[epoch 013 | step 0300] train_loss=0.1007
[epoch 013 | step 0310] train_loss=0.1185
[epoch 013 | step 0320] train_loss=0.1029
[epoch 013 | step 0330] train_loss=0.1245
[epoch 013 | step 0340] train_loss=0.1386
[epoch 013 | step 0350] train_loss=0.1418
[epoch 013 | step 0360] train_loss=0.1263
[epoch 013 | step 0370] train_loss=0.1465
[epoch 013 | step 0380] train_loss=0.1278
[epoch 013 | step 0390] train_loss=0.1367
[epoch 013] train_loss=0.1367 | dev_loss=0.1381 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 013] No EER improvement for 3 epoch(s) (best=0.02%)
[epoch 014 | step 0010] train_loss=0.1169
[epoch 014 | step 0020] train_loss=0.1068
[epoch 014 | step 0030] train_loss=0.1211
[epoch 014 | step 0040] train_loss=0.1196
[epoch 014 | step 0050] train_loss=0.1092
[epoch 014 | step 0060] train_loss=0.1054
[epoch 014 | step 0070] train_loss=0.0734
[epoch 014 | step 0080] train_loss=0.1442
[epoch 014 | step 0090] train_loss=0.0843
[epoch 014 | step 0100] train_loss=0.1293
[epoch 014 | step 0110] train_loss=0.1038
[epoch 014 | step 0120] train_loss=0.1125
[epoch 014 | step 0130] train_loss=0.1560
[epoch 014 | step 0140] train_loss=0.1503
[epoch 014 | step 0150] train_loss=0.1075
[epoch 014 | step 0160] train_loss=0.1125
[epoch 014 | step 0170] train_loss=0.1060
[epoch 014 | step 0180] train_loss=0.1542
[epoch 014 | step 0190] train_loss=0.1413
[epoch 014 | step 0200] train_loss=0.0867
[epoch 014 | step 0210] train_loss=0.1156
[epoch 014 | step 0220] train_loss=0.1203
[epoch 014 | step 0230] train_loss=0.1211
[epoch 014 | step 0240] train_loss=0.1216
[epoch 014 | step 0250] train_loss=0.1126
[epoch 014 | step 0260] train_loss=0.0776
[epoch 014 | step 0270] train_loss=0.1647
[epoch 014 | step 0280] train_loss=0.1314
[epoch 014 | step 0290] train_loss=0.0838
[epoch 014 | step 0300] train_loss=0.1252
[epoch 014 | step 0310] train_loss=0.1034
[epoch 014 | step 0320] train_loss=0.0939
[epoch 014 | step 0330] train_loss=0.1304
[epoch 014 | step 0340] train_loss=0.1051
[epoch 014 | step 0350] train_loss=0.1444
[epoch 014 | step 0360] train_loss=0.1088
[epoch 014 | step 0370] train_loss=0.0869
[epoch 014 | step 0380] train_loss=0.0939
[epoch 014 | step 0390] train_loss=0.0722
[epoch 014] train_loss=0.1174 | dev_loss=0.1197 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 014] No EER improvement for 4 epoch(s) (best=0.02%)
[epoch 015 | step 0010] train_loss=0.1000
[epoch 015 | step 0020] train_loss=0.0916
[epoch 015 | step 0030] train_loss=0.1066
[epoch 015 | step 0040] train_loss=0.1266
[epoch 015 | step 0050] train_loss=0.0844
[epoch 015 | step 0060] train_loss=0.0982
[epoch 015 | step 0070] train_loss=0.1152
[epoch 015 | step 0080] train_loss=0.1285
[epoch 015 | step 0090] train_loss=0.1198
[epoch 015 | step 0100] train_loss=0.0858
[epoch 015 | step 0110] train_loss=0.1248
[epoch 015 | step 0120] train_loss=0.0857
[epoch 015 | step 0130] train_loss=0.1079
[epoch 015 | step 0140] train_loss=0.0786
[epoch 015 | step 0150] train_loss=0.1268
[epoch 015 | step 0160] train_loss=0.0961
[epoch 015 | step 0170] train_loss=0.1147
[epoch 015 | step 0180] train_loss=0.1035
[epoch 015 | step 0190] train_loss=0.1151
[epoch 015 | step 0200] train_loss=0.0970
[epoch 015 | step 0210] train_loss=0.1142
[epoch 015 | step 0220] train_loss=0.0825
[epoch 015 | step 0230] train_loss=0.1116
[epoch 015 | step 0240] train_loss=0.0687
[epoch 015 | step 0250] train_loss=0.1286
[epoch 015 | step 0260] train_loss=0.1206
[epoch 015 | step 0270] train_loss=0.1246
[epoch 015 | step 0280] train_loss=0.0929
[epoch 015 | step 0290] train_loss=0.0935
[epoch 015 | step 0300] train_loss=0.0688
[epoch 015 | step 0310] train_loss=0.0853
[epoch 015 | step 0320] train_loss=0.0659
[epoch 015 | step 0330] train_loss=0.0807
[epoch 015 | step 0340] train_loss=0.1050
[epoch 015 | step 0350] train_loss=0.0918
[epoch 015 | step 0360] train_loss=0.0985
[epoch 015 | step 0370] train_loss=0.1087
[epoch 015 | step 0380] train_loss=0.1019
[epoch 015 | step 0390] train_loss=0.0774
[epoch 015] train_loss=0.1010 | dev_loss=0.1040 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 015] No EER improvement for 5 epoch(s) (best=0.02%)
[epoch 016 | step 0010] train_loss=0.0700
[epoch 016 | step 0020] train_loss=0.0930
[epoch 016 | step 0030] train_loss=0.0878
[epoch 016 | step 0040] train_loss=0.0877
[epoch 016 | step 0050] train_loss=0.0966
[epoch 016 | step 0060] train_loss=0.0802
[epoch 016 | step 0070] train_loss=0.0707
[epoch 016 | step 0080] train_loss=0.0703
[epoch 016 | step 0090] train_loss=0.0802
[epoch 016 | step 0100] train_loss=0.1120
[epoch 016 | step 0110] train_loss=0.0829
[epoch 016 | step 0120] train_loss=0.0780
[epoch 016 | step 0130] train_loss=0.0967
[epoch 016 | step 0140] train_loss=0.0793
[epoch 016 | step 0150] train_loss=0.0896
[epoch 016 | step 0160] train_loss=0.0783
[epoch 016 | step 0170] train_loss=0.0767
[epoch 016 | step 0180] train_loss=0.1113
[epoch 016 | step 0190] train_loss=0.0900
[epoch 016 | step 0200] train_loss=0.0934
[epoch 016 | step 0210] train_loss=0.0733
[epoch 016 | step 0220] train_loss=0.0783
[epoch 016 | step 0230] train_loss=0.0577
[epoch 016 | step 0240] train_loss=0.0621
[epoch 016 | step 0250] train_loss=0.0694
[epoch 016 | step 0260] train_loss=0.0832
[epoch 016 | step 0270] train_loss=0.0832
[epoch 016 | step 0280] train_loss=0.0823
[epoch 016 | step 0290] train_loss=0.0645
[epoch 016 | step 0300] train_loss=0.0886
[epoch 016 | step 0310] train_loss=0.0717
[epoch 016 | step 0320] train_loss=0.1069
[epoch 016 | step 0330] train_loss=0.0626
[epoch 016 | step 0340] train_loss=0.0973
[epoch 016 | step 0350] train_loss=0.0776
[epoch 016 | step 0360] train_loss=0.1052
[epoch 016 | step 0370] train_loss=0.0805
[epoch 016 | step 0380] train_loss=0.0538
[epoch 016 | step 0390] train_loss=0.0726
[epoch 016] train_loss=0.0870 | dev_loss=0.0906 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 016] No EER improvement for 6 epoch(s) (best=0.02%)
[epoch 017 | step 0010] train_loss=0.0895
[epoch 017 | step 0020] train_loss=0.1021
[epoch 017 | step 0030] train_loss=0.1066
[epoch 017 | step 0040] train_loss=0.0803
[epoch 017 | step 0050] train_loss=0.1158
[epoch 017 | step 0060] train_loss=0.0724
[epoch 017 | step 0070] train_loss=0.0690
[epoch 017 | step 0080] train_loss=0.0663
[epoch 017 | step 0090] train_loss=0.0753
[epoch 017 | step 0100] train_loss=0.0682
[epoch 017 | step 0110] train_loss=0.0813
[epoch 017 | step 0120] train_loss=0.0736
[epoch 017 | step 0130] train_loss=0.0860
[epoch 017 | step 0140] train_loss=0.0599
[epoch 017 | step 0150] train_loss=0.0825
[epoch 017 | step 0160] train_loss=0.0773
[epoch 017 | step 0170] train_loss=0.0557
[epoch 017 | step 0180] train_loss=0.0862
[epoch 017 | step 0190] train_loss=0.0696
[epoch 017 | step 0200] train_loss=0.1537
[epoch 017 | step 0210] train_loss=0.1023
[epoch 017 | step 0220] train_loss=0.0986
[epoch 017 | step 0230] train_loss=0.0616
[epoch 017 | step 0240] train_loss=0.0819
[epoch 017 | step 0250] train_loss=0.0633
[epoch 017 | step 0260] train_loss=0.0576
[epoch 017 | step 0270] train_loss=0.0924
[epoch 017 | step 0280] train_loss=0.0688
[epoch 017 | step 0290] train_loss=0.0960
[epoch 017 | step 0300] train_loss=0.0714
[epoch 017 | step 0310] train_loss=0.0602
[epoch 017 | step 0320] train_loss=0.0828
[epoch 017 | step 0330] train_loss=0.0622
[epoch 017 | step 0340] train_loss=0.0520
[epoch 017 | step 0350] train_loss=0.0708
[epoch 017 | step 0360] train_loss=0.0715
[epoch 017 | step 0370] train_loss=0.0899
[epoch 017 | step 0380] train_loss=0.0783
[epoch 017 | step 0390] train_loss=0.0581
[epoch 017] train_loss=0.0750 | dev_loss=0.0790 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 017] No EER improvement for 7 epoch(s) (best=0.02%)
[epoch 018 | step 0010] train_loss=0.0934
[epoch 018 | step 0020] train_loss=0.0476
[epoch 018 | step 0030] train_loss=0.0630
[epoch 018 | step 0040] train_loss=0.0724
[epoch 018 | step 0050] train_loss=0.0723
[epoch 018 | step 0060] train_loss=0.0656
[epoch 018 | step 0070] train_loss=0.0774
[epoch 018 | step 0080] train_loss=0.0768
[epoch 018 | step 0090] train_loss=0.0580
[epoch 018 | step 0100] train_loss=0.0810
[epoch 018 | step 0110] train_loss=0.0741
[epoch 018 | step 0120] train_loss=0.0698
[epoch 018 | step 0130] train_loss=0.0550
[epoch 018 | step 0140] train_loss=0.0554
[epoch 018 | step 0150] train_loss=0.0657
[epoch 018 | step 0160] train_loss=0.0530
[epoch 018 | step 0170] train_loss=0.0742
[epoch 018 | step 0180] train_loss=0.0688
[epoch 018 | step 0190] train_loss=0.0536
[epoch 018 | step 0200] train_loss=0.0479
[epoch 018 | step 0210] train_loss=0.0500
[epoch 018 | step 0220] train_loss=0.0773
[epoch 018 | step 0230] train_loss=0.0553
[epoch 018 | step 0240] train_loss=0.0710
[epoch 018 | step 0250] train_loss=0.0751
[epoch 018 | step 0260] train_loss=0.0600
[epoch 018 | step 0270] train_loss=0.0553
[epoch 018 | step 0280] train_loss=0.0577
[epoch 018 | step 0290] train_loss=0.0609
[epoch 018 | step 0300] train_loss=0.0584
[epoch 018 | step 0310] train_loss=0.0512
[epoch 018 | step 0320] train_loss=0.0823
[epoch 018 | step 0330] train_loss=0.0498
[epoch 018 | step 0340] train_loss=0.0531
[epoch 018 | step 0350] train_loss=0.0638
[epoch 018 | step 0360] train_loss=0.0766
[epoch 018 | step 0370] train_loss=0.0944
[epoch 018 | step 0380] train_loss=0.0915
[epoch 018 | step 0390] train_loss=0.0545
[epoch 018] train_loss=0.0648 | dev_loss=0.0691 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 018] No EER improvement for 8 epoch(s) (best=0.02%)
[epoch 019 | step 0010] train_loss=0.0766
[epoch 019 | step 0020] train_loss=0.0517
[epoch 019 | step 0030] train_loss=0.0441
[epoch 019 | step 0040] train_loss=0.0486
[epoch 019 | step 0050] train_loss=0.0635
[epoch 019 | step 0060] train_loss=0.0676
[epoch 019 | step 0070] train_loss=0.0534
[epoch 019 | step 0080] train_loss=0.0530
[epoch 019 | step 0090] train_loss=0.0581
[epoch 019 | step 0100] train_loss=0.0655
[epoch 019 | step 0110] train_loss=0.0708
[epoch 019 | step 0120] train_loss=0.0484
[epoch 019 | step 0130] train_loss=0.0483
[epoch 019 | step 0140] train_loss=0.0681
[epoch 019 | step 0150] train_loss=0.0476
[epoch 019 | step 0160] train_loss=0.0771
[epoch 019 | step 0170] train_loss=0.0615
[epoch 019 | step 0180] train_loss=0.0666
[epoch 019 | step 0190] train_loss=0.0396
[epoch 019 | step 0200] train_loss=0.0383
[epoch 019 | step 0210] train_loss=0.0480
[epoch 019 | step 0220] train_loss=0.0522
[epoch 019 | step 0230] train_loss=0.0436
[epoch 019 | step 0240] train_loss=0.0550
[epoch 019 | step 0250] train_loss=0.0485
[epoch 019 | step 0260] train_loss=0.0533
[epoch 019 | step 0270] train_loss=0.0524
[epoch 019 | step 0280] train_loss=0.0597
[epoch 019 | step 0290] train_loss=0.0722
[epoch 019 | step 0300] train_loss=0.0599
[epoch 019 | step 0310] train_loss=0.0538
[epoch 019 | step 0320] train_loss=0.0494
[epoch 019 | step 0330] train_loss=0.0458
[epoch 019 | step 0340] train_loss=0.0576
[epoch 019 | step 0350] train_loss=0.0570
[epoch 019 | step 0360] train_loss=0.0509
[epoch 019 | step 0370] train_loss=0.0512
[epoch 019 | step 0380] train_loss=0.0419
[epoch 019 | step 0390] train_loss=0.0320
[epoch 019] train_loss=0.0560 | dev_loss=0.0605 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 019] No EER improvement for 9 epoch(s) (best=0.02%)
[epoch 020 | step 0010] train_loss=0.0499
[epoch 020 | step 0020] train_loss=0.0509
[epoch 020 | step 0030] train_loss=0.0537
[epoch 020 | step 0040] train_loss=0.0521
[epoch 020 | step 0050] train_loss=0.0394
[epoch 020 | step 0060] train_loss=0.0382
[epoch 020 | step 0070] train_loss=0.0440
[epoch 020 | step 0080] train_loss=0.0390
[epoch 020 | step 0090] train_loss=0.0407
[epoch 020 | step 0100] train_loss=0.0429
[epoch 020 | step 0110] train_loss=0.0416
[epoch 020 | step 0120] train_loss=0.0367
[epoch 020 | step 0130] train_loss=0.0514
[epoch 020 | step 0140] train_loss=0.0313
[epoch 020 | step 0150] train_loss=0.0409
[epoch 020 | step 0160] train_loss=0.0485
[epoch 020 | step 0170] train_loss=0.0503
[epoch 020 | step 0180] train_loss=0.0469
[epoch 020 | step 0190] train_loss=0.0363
[epoch 020 | step 0200] train_loss=0.0276
[epoch 020 | step 0210] train_loss=0.0451
[epoch 020 | step 0220] train_loss=0.0376
[epoch 020 | step 0230] train_loss=0.0351
[epoch 020 | step 0240] train_loss=0.0516
[epoch 020 | step 0250] train_loss=0.0404
[epoch 020 | step 0260] train_loss=0.0639
[epoch 020 | step 0270] train_loss=0.0314
[epoch 020 | step 0280] train_loss=0.0406
[epoch 020 | step 0290] train_loss=0.0385
[epoch 020 | step 0300] train_loss=0.0447
[epoch 020 | step 0310] train_loss=0.0413
[epoch 020 | step 0320] train_loss=0.0445
[epoch 020 | step 0330] train_loss=0.0422
[epoch 020 | step 0340] train_loss=0.0275
[epoch 020 | step 0350] train_loss=0.0549
[epoch 020 | step 0360] train_loss=0.0501
[epoch 020 | step 0370] train_loss=0.0539
[epoch 020 | step 0380] train_loss=0.0526
[epoch 020 | step 0390] train_loss=0.0402
[epoch 020] train_loss=0.0485 | dev_loss=0.0531 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 020] No EER improvement for 10 epoch(s) (best=0.02%)
[epoch 021 | step 0010] train_loss=0.0540
[epoch 021 | step 0020] train_loss=0.0402
[epoch 021 | step 0030] train_loss=0.0299
[epoch 021 | step 0040] train_loss=0.0343
[epoch 021 | step 0050] train_loss=0.0912
[epoch 021 | step 0060] train_loss=0.0406
[epoch 021 | step 0070] train_loss=0.0553
[epoch 021 | step 0080] train_loss=0.0459
[epoch 021 | step 0090] train_loss=0.0396
[epoch 021 | step 0100] train_loss=0.0530
[epoch 021 | step 0110] train_loss=0.0355
[epoch 021 | step 0120] train_loss=0.0298
[epoch 021 | step 0130] train_loss=0.0433
[epoch 021 | step 0140] train_loss=0.0364
[epoch 021 | step 0150] train_loss=0.0442
[epoch 021 | step 0160] train_loss=0.0366
[epoch 021 | step 0170] train_loss=0.0431
[epoch 021 | step 0180] train_loss=0.0364
[epoch 021 | step 0190] train_loss=0.0360
[epoch 021 | step 0200] train_loss=0.0653
[epoch 021 | step 0210] train_loss=0.0369
[epoch 021 | step 0220] train_loss=0.0290
[epoch 021 | step 0230] train_loss=0.0467
[epoch 021 | step 0240] train_loss=0.0374
[epoch 021 | step 0250] train_loss=0.0437
[epoch 021 | step 0260] train_loss=0.0393
[epoch 021 | step 0270] train_loss=0.0465
[epoch 021 | step 0280] train_loss=0.0395
[epoch 021 | step 0290] train_loss=0.0351
[epoch 021 | step 0300] train_loss=0.0380
[epoch 021 | step 0310] train_loss=0.0369
[epoch 021 | step 0320] train_loss=0.0320
[epoch 021 | step 0330] train_loss=0.0351
[epoch 021 | step 0340] train_loss=0.0397
[epoch 021 | step 0350] train_loss=0.0275
[epoch 021 | step 0360] train_loss=0.0479
[epoch 021 | step 0370] train_loss=0.0430
[epoch 021 | step 0380] train_loss=0.0460
[epoch 021 | step 0390] train_loss=0.0379
[epoch 021] train_loss=0.0420 | dev_loss=0.0466 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 021] No EER improvement for 11 epoch(s) (best=0.02%)
[epoch 022 | step 0010] train_loss=0.0280
[epoch 022 | step 0020] train_loss=0.0462
[epoch 022 | step 0030] train_loss=0.0411
[epoch 022 | step 0040] train_loss=0.0431
[epoch 022 | step 0050] train_loss=0.0371
[epoch 022 | step 0060] train_loss=0.0509
[epoch 022 | step 0070] train_loss=0.0341
[epoch 022 | step 0080] train_loss=0.0362
[epoch 022 | step 0090] train_loss=0.0441
[epoch 022 | step 0100] train_loss=0.0325
[epoch 022 | step 0110] train_loss=0.0223
[epoch 022 | step 0120] train_loss=0.0331
[epoch 022 | step 0130] train_loss=0.0406
[epoch 022 | step 0140] train_loss=0.0492
[epoch 022 | step 0150] train_loss=0.0347
[epoch 022 | step 0160] train_loss=0.0286
[epoch 022 | step 0170] train_loss=0.0433
[epoch 022 | step 0180] train_loss=0.0319
[epoch 022 | step 0190] train_loss=0.0472
[epoch 022 | step 0200] train_loss=0.0288
[epoch 022 | step 0210] train_loss=0.0362
[epoch 022 | step 0220] train_loss=0.0485
[epoch 022 | step 0230] train_loss=0.0306
[epoch 022 | step 0240] train_loss=0.0370
[epoch 022 | step 0250] train_loss=0.0307
[epoch 022 | step 0260] train_loss=0.0331
[epoch 022 | step 0270] train_loss=0.0265
[epoch 022 | step 0280] train_loss=0.0453
[epoch 022 | step 0290] train_loss=0.0317
[epoch 022 | step 0300] train_loss=0.0300
[epoch 022 | step 0310] train_loss=0.0314
[epoch 022 | step 0320] train_loss=0.0328
[epoch 022 | step 0330] train_loss=0.0386
[epoch 022 | step 0340] train_loss=0.0430
[epoch 022 | step 0350] train_loss=0.0413
[epoch 022 | step 0360] train_loss=0.0297
[epoch 022 | step 0370] train_loss=0.0297
[epoch 022 | step 0380] train_loss=0.0303
[epoch 022 | step 0390] train_loss=0.0302
[epoch 022] train_loss=0.0365 | dev_loss=0.0411 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 022] No EER improvement for 12 epoch(s) (best=0.02%)
[epoch 023 | step 0010] train_loss=0.0299
[epoch 023 | step 0020] train_loss=0.0345
[epoch 023 | step 0030] train_loss=0.0310
[epoch 023 | step 0040] train_loss=0.0298
[epoch 023 | step 0050] train_loss=0.0341
[epoch 023 | step 0060] train_loss=0.0272
[epoch 023 | step 0070] train_loss=0.0424
[epoch 023 | step 0080] train_loss=0.0274
[epoch 023 | step 0090] train_loss=0.0286
[epoch 023 | step 0100] train_loss=0.0238
[epoch 023 | step 0110] train_loss=0.0343
[epoch 023 | step 0120] train_loss=0.0306
[epoch 023 | step 0130] train_loss=0.0198
[epoch 023 | step 0140] train_loss=0.0334
[epoch 023 | step 0150] train_loss=0.0264
[epoch 023 | step 0160] train_loss=0.0247
[epoch 023 | step 0170] train_loss=0.0292
[epoch 023 | step 0180] train_loss=0.0269
[epoch 023 | step 0190] train_loss=0.0312
[epoch 023 | step 0200] train_loss=0.0312
[epoch 023 | step 0210] train_loss=0.0359
[epoch 023 | step 0220] train_loss=0.0295
[epoch 023 | step 0230] train_loss=0.0240
[epoch 023 | step 0240] train_loss=0.0218
[epoch 023 | step 0250] train_loss=0.0393
[epoch 023 | step 0260] train_loss=0.0273
[epoch 023 | step 0270] train_loss=0.0261
[epoch 023 | step 0280] train_loss=0.0338
[epoch 023 | step 0290] train_loss=0.0413
[epoch 023 | step 0300] train_loss=0.0311
[epoch 023 | step 0310] train_loss=0.0322
[epoch 023 | step 0320] train_loss=0.0323
[epoch 023 | step 0330] train_loss=0.0318
[epoch 023 | step 0340] train_loss=0.0273
[epoch 023 | step 0350] train_loss=0.0195
[epoch 023 | step 0360] train_loss=0.0248
[epoch 023 | step 0370] train_loss=0.0244
[epoch 023 | step 0380] train_loss=0.0341
[epoch 023 | step 0390] train_loss=0.0219
[epoch 023] train_loss=0.0316 | dev_loss=0.0363 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 023] No EER improvement for 13 epoch(s) (best=0.02%)
[epoch 024 | step 0010] train_loss=0.0290
[epoch 024 | step 0020] train_loss=0.0384
[epoch 024 | step 0030] train_loss=0.0232
[epoch 024 | step 0040] train_loss=0.0251
[epoch 024 | step 0050] train_loss=0.0313
[epoch 024 | step 0060] train_loss=0.0342
[epoch 024 | step 0070] train_loss=0.0236
[epoch 024 | step 0080] train_loss=0.0267
[epoch 024 | step 0090] train_loss=0.0467
[epoch 024 | step 0100] train_loss=0.0198
[epoch 024 | step 0110] train_loss=0.0342
[epoch 024 | step 0120] train_loss=0.0231
[epoch 024 | step 0130] train_loss=0.0233
[epoch 024 | step 0140] train_loss=0.0356
[epoch 024 | step 0150] train_loss=0.0236
[epoch 024 | step 0160] train_loss=0.0245
[epoch 024 | step 0170] train_loss=0.0280
[epoch 024 | step 0180] train_loss=0.0360
[epoch 024 | step 0190] train_loss=0.0236
[epoch 024 | step 0200] train_loss=0.0258
[epoch 024 | step 0210] train_loss=0.0210
[epoch 024 | step 0220] train_loss=0.0293
[epoch 024 | step 0230] train_loss=0.0265
[epoch 024 | step 0240] train_loss=0.0248
[epoch 024 | step 0250] train_loss=0.0181
[epoch 024 | step 0260] train_loss=0.0226
[epoch 024 | step 0270] train_loss=0.0315
[epoch 024 | step 0280] train_loss=0.0257
[epoch 024 | step 0290] train_loss=0.0209
[epoch 024 | step 0300] train_loss=0.0165
[epoch 024 | step 0310] train_loss=0.0214
[epoch 024 | step 0320] train_loss=0.0248
[epoch 024 | step 0330] train_loss=0.0225
[epoch 024 | step 0340] train_loss=0.0235
[epoch 024 | step 0350] train_loss=0.0228
[epoch 024 | step 0360] train_loss=0.0163
[epoch 024 | step 0370] train_loss=0.0388
[epoch 024 | step 0380] train_loss=0.0341
[epoch 024 | step 0390] train_loss=0.0248
[epoch 024] train_loss=0.0275 | dev_loss=0.0322 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 024] No EER improvement for 14 epoch(s) (best=0.02%)
[epoch 025 | step 0010] train_loss=0.0278
[epoch 025 | step 0020] train_loss=0.0345
[epoch 025 | step 0030] train_loss=0.0278
[epoch 025 | step 0040] train_loss=0.0283
[epoch 025 | step 0050] train_loss=0.0281
[epoch 025 | step 0060] train_loss=0.0180
[epoch 025 | step 0070] train_loss=0.0247
[epoch 025 | step 0080] train_loss=0.0254
[epoch 025 | step 0090] train_loss=0.0264
[epoch 025 | step 0100] train_loss=0.0232
[epoch 025 | step 0110] train_loss=0.0290
[epoch 025 | step 0120] train_loss=0.0183
[epoch 025 | step 0130] train_loss=0.0268
[epoch 025 | step 0140] train_loss=0.0212
[epoch 025 | step 0150] train_loss=0.0237
[epoch 025 | step 0160] train_loss=0.0226
[epoch 025 | step 0170] train_loss=0.0181
[epoch 025 | step 0180] train_loss=0.0269
[epoch 025 | step 0190] train_loss=0.0228
[epoch 025 | step 0200] train_loss=0.0223
[epoch 025 | step 0210] train_loss=0.0234
[epoch 025 | step 0220] train_loss=0.0270
[epoch 025 | step 0230] train_loss=0.0205
[epoch 025 | step 0240] train_loss=0.0159
[epoch 025 | step 0250] train_loss=0.0272
[epoch 025 | step 0260] train_loss=0.0223
[epoch 025 | step 0270] train_loss=0.0273
[epoch 025 | step 0280] train_loss=0.0218
[epoch 025 | step 0290] train_loss=0.0257
[epoch 025 | step 0300] train_loss=0.0200
[epoch 025 | step 0310] train_loss=0.0229
[epoch 025 | step 0320] train_loss=0.0234
[epoch 025 | step 0330] train_loss=0.0213
[epoch 025 | step 0340] train_loss=0.0203
[epoch 025 | step 0350] train_loss=0.0233
[epoch 025 | step 0360] train_loss=0.0219
[epoch 025 | step 0370] train_loss=0.0280
[epoch 025 | step 0380] train_loss=0.0232
[epoch 025 | step 0390] train_loss=0.0261
[epoch 025] train_loss=0.0239 | dev_loss=0.0286 | dev_acc=99.98% | dev_auc=1.0000 | dev_eer=0.02%
[epoch 025] No EER improvement for 15 epoch(s) (best=0.02%)
[EARLY STOP] Patience reached (15) with no EER improvement. Best EER = 0.02%
==> Stage-2 training complete.
Best classifier checkpoint: checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
Using device: cuda
Loading Stage-2 checkpoint from: checkpoints_stage2/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/stage2_binary_head_best.pt
Loaded Stage-2 head: type=linear, in_dim=256, hidden_dim=128, dropout=0.2
Loading embeddings from: /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ASV/supcon_uniformity_weight_0.1/eval_embeddings.npy
Total samples: 71237, emb_dim=256
Writing scores to: /home/jsudan/wav2vec_contr_loss/scores/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/score_cm_eval.txt
Scoring asv_eval:   0%|          | 0/279 [00:00<?, ?it/s]Scoring asv_eval:   7%|▋         | 20/279 [00:00<00:01, 199.74it/s]Scoring asv_eval:  77%|███████▋  | 215/279 [00:00<00:00, 1225.74it/s]Scoring asv_eval: 100%|██████████| 279/279 [00:00<00:00, 1194.05it/s]
Done writing scores: /home/jsudan/wav2vec_contr_loss/scores/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/score_cm_eval.txt
Loading embeddings from: /scratch/hafiz_root/hafiz1/jsudan/encoder_embeddings/stage1_embeddings/ITW/supcon_uniformity_weight_0.1/itw_embeddings.npy
Total samples: 31779, emb_dim=256
Writing scores to: /home/jsudan/wav2vec_contr_loss/scores/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/score_cm_itw.txt
Scoring itw:   0%|          | 0/125 [00:00<?, ?it/s]Scoring itw: 100%|██████████| 125/125 [00:00<00:00, 1922.63it/s]
Done writing scores: /home/jsudan/wav2vec_contr_loss/scores/supcon_uniformity_weight_0.1/facebook/wav2vec2-xls-r-300m/score_cm_itw.txt
All requested score files handled (generated or skipped).
----------------------------------------------------------------
Training script finished.
Job finished at: Wed Dec 31 06:45:10 EST 2025
