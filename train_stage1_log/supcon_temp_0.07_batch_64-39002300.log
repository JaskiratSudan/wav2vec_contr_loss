Setting up the environment...
Job started on gl1502.arc-ts.umich.edu at Sun Dec 28 18:06:35 EST 2025
Python version: Python 3.9.7
PyTorch version: 2.8.0+cu128
CUDA available: True
Current GPU: NVIDIA A40
NVIDIA A40
----------------------------------------------------------------
EXPERIMENT NAME: supcon_temp_0.07_batch_64
W1228 18:06:43.269420 3084393 torch/distributed/run.py:774] 
W1228 18:06:43.269420 3084393 torch/distributed/run.py:774] *****************************************
W1228 18:06:43.269420 3084393 torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1228 18:06:43.269420 3084393 torch/distributed/run.py:774] *****************************************
[W1228 18:06:43.235223736 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [localhost]:46025 (errno: 97 - Address family not supported by protocol).
[W1228 18:06:43.236277846 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [localhost]:46025 (errno: 97 - Address family not supported by protocol).
[W1228 18:06:43.237321804 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [localhost]:46025 (errno: 97 - Address family not supported by protocol).
[W1228 18:06:43.443141205 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [gl1502.arc-ts.umich.edu]:38119 (errno: 97 - Address family not supported by protocol).
[W1228 18:06:52.040874293 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [gl1502.arc-ts.umich.edu]:38119 (errno: 97 - Address family not supported by protocol).
[W1228 18:06:52.041020423 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [gl1502.arc-ts.umich.edu]:38119 (errno: 97 - Address family not supported by protocol).
=== CONFIG ===
MODEL_NAME=facebook/wav2vec2-xls-r-300m
SAVE_DIR=/home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_temp_0.07_batch_64/facebook__wav2vec2-xls-r-300m
TRAIN_ROOT=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_LA_train/flac
TRAIN_PROTOCOL=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_train_protocol_with_speaker.txt
DEV_ROOT=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_LA_dev/flac
DEV_PROTOCOL=/nfs/turbo/umd-hafiz/issf_server_data/AsvSpoofData_2019/train/LA/ASVspoof2019_dev_protocol_with_speaker.txt
TARGET_SAMPLE_RATE=16000
MAX_DURATION_SECONDS=5
INPUT_DIM=1024
HIDDEN_DIM=256
DROPOUT=0.1
EPOCHS=100
BATCH_SIZE=64
NUM_SAMPLES=None
HEAD_LR=0.005
ENC_LR=1e-05
WEIGHT_DECAY=0.003
TEMPERATURE=0.07
NUM_WORKERS=4
SEED=1337
UNIFORMITY_WEIGHT=0.0
UNIFORMITY_T=2.0
SUPCON_SIMILARITY=cosine
TOPK_NEG=15
WARMUP_EPOCHS=100
ALPHA_END=1.0
ALPHA_RAMP_EPOCHS=80
USE_RAWBOOST=True
RAWBOOST_PROB=0.7
FINETUNE_ENCODER=True
DISTRIBUTED=True | WORLD_SIZE=2 | RANK=0
=============
Using device: cuda:0 | RawBoost=True (p=0.7)
CUDA device count: 2
[rank1]:[W1228 18:07:01.979243284 reducer.cpp:1457] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W1228 18:07:01.471882672 reducer.cpp:1457] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/jsudan/wav2vec_contr_loss/train_stage1.py", line 156, in <module>
[rank1]:     main()
[rank1]:   File "/home/jsudan/wav2vec_contr_loss/train_stage1.py", line 122, in main
[rank1]:     train_loss, alpha = train_one_epoch(
[rank1]:   File "/home/jsudan/wav2vec_contr_loss/stage1_utils.py", line 118, in train_one_epoch
[rank1]:     hs = encoder(waveforms, attention_mask=attn)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1648, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1474, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/wav2vec_contr_loss/encoder.py", line 57, in forward
[rank1]:     out = self.model(
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1467, in forward
[rank1]:     encoder_outputs = self.encoder(
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 831, in forward
[rank1]:     layer_outputs = layer(
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/modeling_layers.py", line 93, in __call__
[rank1]:     return super().__call__(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 669, in forward
[rank1]:     hidden_states, attn_weights, _ = self.attention(
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 576, in forward
[rank1]:     attn_output = self.out_proj(attn_output)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
[rank1]:     return F.linear(input, self.weight, self.bias)
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 44.43 GiB of which 64.62 MiB is free. Including non-PyTorch memory, this process has 44.36 GiB memory in use. Of the allocated memory 43.55 GiB is allocated by PyTorch, and 363.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/jsudan/wav2vec_contr_loss/train_stage1.py", line 156, in <module>
[rank0]:     main()
[rank0]:   File "/home/jsudan/wav2vec_contr_loss/train_stage1.py", line 122, in main
[rank0]:     train_loss, alpha = train_one_epoch(
[rank0]:   File "/home/jsudan/wav2vec_contr_loss/stage1_utils.py", line 118, in train_one_epoch
[rank0]:     hs = encoder(waveforms, attention_mask=attn)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1648, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1474, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/wav2vec_contr_loss/encoder.py", line 57, in forward
[rank0]:     out = self.model(
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1467, in forward
[rank0]:     encoder_outputs = self.encoder(
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 831, in forward
[rank0]:     layer_outputs = layer(
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/modeling_layers.py", line 93, in __call__
[rank0]:     return super().__call__(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 669, in forward
[rank0]:     hidden_states, attn_weights, _ = self.attention(
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 576, in forward
[rank0]:     attn_output = self.out_proj(attn_output)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
[rank0]:     return F.linear(input, self.weight, self.bias)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 44.43 GiB of which 64.62 MiB is free. Including non-PyTorch memory, this process has 44.36 GiB memory in use. Of the allocated memory 43.55 GiB is allocated by PyTorch, and 363.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1228 18:07:08.986026806 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1228 18:07:08.891826 3084393 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3084408 closing signal SIGTERM
E1228 18:07:09.256194 3084393 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 1 (pid: 3084409) of binary: /home/jsudan/myenv/bin/python
Traceback (most recent call last):
  File "/home/jsudan/myenv/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_stage1.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-12-28_18:07:08
  host      : gl1502.arc-ts.umich.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3084409)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[ERROR] Stage-1 checkpoint not found: /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon_temp_0.07_batch_64/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt
