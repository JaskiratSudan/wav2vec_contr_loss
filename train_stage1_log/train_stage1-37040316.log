Setting up the environment...
Job started on gl1515.arc-ts.umich.edu at Mon Dec  1 19:28:54 EST 2025
Python version: Python 3.9.7
PyTorch version: 2.8.0+cu128
CUDA available: True
Current GPU: NVIDIA A40
----------------------------------------------------------------
Starting the Python training script...
Model: facebook/wav2vec2-xls-r-300m
Using device: cuda | RawBoost=True (p=0.9)
[epoch 001] alpha=0.00 | train_loss=5.2508 | dev_loss=4.9818
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.9818)
[epoch 002] alpha=0.00 | train_loss=4.9862 | dev_loss=5.0217
[epoch 003] alpha=0.00 | train_loss=4.9162 | dev_loss=4.8632
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8632)
[epoch 004] alpha=0.00 | train_loss=4.8940 | dev_loss=4.8477
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8477)
[epoch 005] alpha=0.00 | train_loss=4.8673 | dev_loss=4.8365
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8365)
[epoch 006] alpha=0.00 | train_loss=4.8704 | dev_loss=4.8461
[epoch 007] alpha=0.00 | train_loss=4.8561 | dev_loss=4.8402
[epoch 008] alpha=0.00 | train_loss=4.8615 | dev_loss=4.8371
[epoch 009] alpha=0.01 | train_loss=4.8557 | dev_loss=4.9747
[epoch 010] alpha=0.03 | train_loss=4.8569 | dev_loss=4.8298
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8298)
[epoch 011] alpha=0.04 | train_loss=4.8537 | dev_loss=4.8273
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8273)
[epoch 012] alpha=0.05 | train_loss=4.8415 | dev_loss=4.8337
[epoch 013] alpha=0.06 | train_loss=4.8404 | dev_loss=4.8282
[epoch 014] alpha=0.07 | train_loss=4.8459 | dev_loss=4.8566
[epoch 015] alpha=0.09 | train_loss=4.8477 | dev_loss=4.8283
[epoch 016] alpha=0.10 | train_loss=4.8511 | dev_loss=4.8384
[epoch 017] alpha=0.11 | train_loss=4.8383 | dev_loss=4.8329
[epoch 018] alpha=0.12 | train_loss=4.8462 | dev_loss=4.9289
[epoch 019] alpha=0.14 | train_loss=4.8460 | dev_loss=4.8277
[epoch 020] alpha=0.15 | train_loss=4.8310 | dev_loss=4.9008
[epoch 021] alpha=0.16 | train_loss=4.8369 | dev_loss=4.8509
[epoch 022] alpha=0.17 | train_loss=4.8364 | dev_loss=4.8215
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8215)
[epoch 023] alpha=0.19 | train_loss=4.8277 | dev_loss=4.8265
[epoch 024] alpha=0.20 | train_loss=4.8302 | dev_loss=4.8274
[epoch 025] alpha=0.21 | train_loss=4.8373 | dev_loss=4.8290
[epoch 026] alpha=0.23 | train_loss=4.8278 | dev_loss=4.8248
[epoch 027] alpha=0.24 | train_loss=4.8229 | dev_loss=4.8178
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8178)
[epoch 028] alpha=0.25 | train_loss=4.8331 | dev_loss=4.8210
[epoch 029] alpha=0.26 | train_loss=4.8292 | dev_loss=4.8353
[epoch 030] alpha=0.28 | train_loss=4.8317 | dev_loss=4.8371
[epoch 031] alpha=0.29 | train_loss=4.8321 | dev_loss=4.8188
[epoch 032] alpha=0.30 | train_loss=4.8361 | dev_loss=4.8311
[epoch 033] alpha=0.31 | train_loss=4.8284 | dev_loss=4.8368
[epoch 034] alpha=0.33 | train_loss=4.8270 | dev_loss=4.8312
[epoch 035] alpha=0.34 | train_loss=4.8236 | dev_loss=4.8227
[epoch 036] alpha=0.35 | train_loss=4.8233 | dev_loss=4.8508
[epoch 037] alpha=0.36 | train_loss=4.8296 | dev_loss=4.9235
[epoch 038] alpha=0.38 | train_loss=4.8243 | dev_loss=4.8143
✓ Saved best -> /home/jsudan/wav2vec_contr_loss/checkpoints_stage1/supcon/with_rawboost/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_stage1_head_best.pt (dev=4.8143)
[epoch 039] alpha=0.39 | train_loss=4.8274 | dev_loss=4.8183
[epoch 040] alpha=0.40 | train_loss=4.8181 | dev_loss=4.8306
[epoch 041] alpha=0.41 | train_loss=4.8240 | dev_loss=4.8418
[epoch 042] alpha=0.42 | train_loss=4.8220 | dev_loss=4.8889
[epoch 043] alpha=0.44 | train_loss=4.8276 | dev_loss=4.8347
[epoch 044] alpha=0.45 | train_loss=4.8260 | dev_loss=4.8165
[epoch 045] alpha=0.46 | train_loss=4.8239 | dev_loss=4.8404
[epoch 046] alpha=0.47 | train_loss=4.8253 | dev_loss=4.8146
[epoch 047] alpha=0.49 | train_loss=4.8208 | dev_loss=4.8188
[epoch 048] alpha=0.50 | train_loss=4.8204 | dev_loss=4.9650
[epoch 049] alpha=0.51 | train_loss=4.8219 | dev_loss=4.8207
[epoch 050] alpha=0.53 | train_loss=4.8200 | dev_loss=4.8171
[epoch 051] alpha=0.54 | train_loss=4.8151 | dev_loss=4.8275
[epoch 052] alpha=0.55 | train_loss=4.8205 | dev_loss=4.8568
[epoch 053] alpha=0.56 | train_loss=4.8203 | dev_loss=4.8266
[epoch 054] alpha=0.57 | train_loss=4.8184 | dev_loss=4.8161
[epoch 055] alpha=0.59 | train_loss=4.8314 | dev_loss=5.0957
[epoch 056] alpha=0.60 | train_loss=4.8238 | dev_loss=4.8175
[epoch 057] alpha=0.61 | train_loss=4.8191 | dev_loss=4.8576
[epoch 058] alpha=0.62 | train_loss=4.8157 | dev_loss=4.8207
[epoch 059] alpha=0.64 | train_loss=4.8192 | dev_loss=4.8199
[epoch 060] alpha=0.65 | train_loss=4.8198 | dev_loss=4.8687
[epoch 061] alpha=0.66 | train_loss=4.8185 | dev_loss=4.8160
[epoch 062] alpha=0.68 | train_loss=4.8235 | dev_loss=4.8207
[epoch 063] alpha=0.69 | train_loss=4.8189 | dev_loss=4.8201
[epoch 064] alpha=0.70 | train_loss=4.8211 | dev_loss=4.8207
[epoch 065] alpha=0.71 | train_loss=4.8148 | dev_loss=4.9192
[epoch 066] alpha=0.72 | train_loss=4.8151 | dev_loss=4.9792
[epoch 067] alpha=0.74 | train_loss=4.8217 | dev_loss=4.8240
[epoch 068] alpha=0.75 | train_loss=4.8171 | dev_loss=4.8152
[epoch 069] alpha=0.76 | train_loss=4.8196 | dev_loss=4.8222
[epoch 070] alpha=0.78 | train_loss=4.8126 | dev_loss=4.8176
[epoch 071] alpha=0.79 | train_loss=4.8157 | dev_loss=4.8485
[epoch 072] alpha=0.80 | train_loss=4.8179 | dev_loss=4.8586
[epoch 073] alpha=0.81 | train_loss=4.8187 | dev_loss=4.8380
[epoch 074] alpha=0.82 | train_loss=4.8146 | dev_loss=4.8293
[epoch 075] alpha=0.84 | train_loss=4.8147 | dev_loss=4.8608
[epoch 076] alpha=0.85 | train_loss=4.8135 | dev_loss=4.8316
[epoch 077] alpha=0.86 | train_loss=4.8159 | dev_loss=4.8609
[epoch 078] alpha=0.88 | train_loss=4.8120 | dev_loss=4.8204
[epoch 079] alpha=0.89 | train_loss=4.8146 | dev_loss=4.8260
[epoch 080] alpha=0.90 | train_loss=4.8132 | dev_loss=4.9001
[epoch 081] alpha=0.91 | train_loss=4.8127 | dev_loss=4.8358
[epoch 082] alpha=0.93 | train_loss=4.8151 | dev_loss=4.8266
[epoch 083] alpha=0.94 | train_loss=4.8139 | dev_loss=4.9193
[epoch 084] alpha=0.95 | train_loss=4.8119 | dev_loss=4.8217
[epoch 085] alpha=0.96 | train_loss=4.8153 | dev_loss=4.8336
[epoch 086] alpha=0.97 | train_loss=4.8127 | dev_loss=4.8227
[epoch 087] alpha=0.99 | train_loss=4.8148 | dev_loss=4.8213
[epoch 088] alpha=1.00 | train_loss=4.8132 | dev_loss=4.8245
[epoch 089] alpha=1.00 | train_loss=4.8125 | dev_loss=4.8239
[epoch 090] alpha=1.00 | train_loss=4.8153 | dev_loss=4.8201
[epoch 091] alpha=1.00 | train_loss=4.8083 | dev_loss=4.8175
slurmstepd: error: *** JOB 37040316 ON gl1515 CANCELLED AT 2025-12-02T05:29:11 DUE TO TIME LIMIT ***
