Setting up the environment...
Job started on gl1526.arc-ts.umich.edu at Sat Dec 27 12:42:51 EST 2025
Python version: Python 3.9.7
PyTorch version: 2.8.0+cu128
CUDA available: True
Current GPU: NVIDIA A40
----------------------------------------------------------------
Starting the Python training script...
/home/jsudan/wav2vec_contr_loss/baseline_train.py:374: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
Model: facebook/wav2vec2-xls-r-300m
Device: cuda | AMP=True | RawBoost=True (p=0.7)
Finetune encoder: True
pos_weight (neg/pos) = 8.5541
/home/jsudan/wav2vec_contr_loss/baseline_train.py:200: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Traceback (most recent call last):
  File "/home/jsudan/wav2vec_contr_loss/baseline_train.py", line 438, in <module>
    main()
  File "/home/jsudan/wav2vec_contr_loss/baseline_train.py", line 382, in main
    train_loss = train_one_epoch(model, loss_fn, train_loader, optimizer, device, scaler)
  File "/home/jsudan/wav2vec_contr_loss/baseline_train.py", line 201, in train_one_epoch
    logits, _ = model(waveforms, attn)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/wav2vec_contr_loss/baseline_train.py", line 171, in forward
    hs = self.encoder(waveforms, attention_mask=attention_mask)   # (B,K,F,T)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/wav2vec_contr_loss/encoder.py", line 57, in forward
    out = self.model(
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1467, in forward
    encoder_outputs = self.encoder(
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 831, in forward
    layer_outputs = layer(
  File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/modeling_layers.py", line 93, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 669, in forward
    hidden_states, attn_weights, _ = self.attention(
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 555, in forward
    key_states = self.k_proj(current_states).view(*kv_input_shape).transpose(1, 2)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jsudan/myenv/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 44.43 GiB of which 2.62 MiB is free. Including non-PyTorch memory, this process has 44.42 GiB memory in use. Of the allocated memory 43.78 GiB is allocated by PyTorch, and 337.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Device: cuda
[OK] Loaded baseline checkpoint: /home/jsudan/wav2vec_contr_loss/checkpoints_baseline/bce/facebook__wav2vec2-xls-r-300m/facebook__wav2vec2-xls-r-300m_baseline_bce_best.pt
Scoring -> score_cm_eval.txt:   0%|          | 0/557 [00:00<?, ?it/s]Scoring -> score_cm_eval.txt:   0%|          | 1/557 [00:03<35:46,  3.86s/it]Scoring -> score_cm_eval.txt:   0%|          | 2/557 [00:05<23:13,  2.51s/it]Scoring -> score_cm_eval.txt:   1%|          | 3/557 [00:06<19:11,  2.08s/it]Scoring -> score_cm_eval.txt:   1%|          | 4/557 [00:08<17:18,  1.88s/it]Scoring -> score_cm_eval.txt:   1%|          | 5/557 [00:10<16:15,  1.77s/it]Scoring -> score_cm_eval.txt:   1%|          | 6/557 [00:11<15:37,  1.70s/it]Scoring -> score_cm_eval.txt:   1%|▏         | 7/557 [00:13<15:10,  1.65s/it]Scoring -> score_cm_eval.txt:   1%|▏         | 8/557 [00:14<14:52,  1.62s/it]Scoring -> score_cm_eval.txt:   2%|▏         | 9/557 [00:16<14:39,  1.60s/it]Scoring -> score_cm_eval.txt:   2%|▏         | 10/557 [00:17<14:32,  1.59s/it]Scoring -> score_cm_eval.txt:   2%|▏         | 11/557 [00:19<14:25,  1.58s/it]Scoring -> score_cm_eval.txt:   2%|▏         | 12/557 [00:21<14:20,  1.58s/it]Scoring -> score_cm_eval.txt:   2%|▏         | 13/557 [00:22<14:16,  1.57s/it]Scoring -> score_cm_eval.txt:   3%|▎         | 14/557 [00:24<14:13,  1.57s/it]Scoring -> score_cm_eval.txt:   3%|▎         | 15/557 [00:25<14:12,  1.57s/it]Scoring -> score_cm_eval.txt:   3%|▎         | 16/557 [00:27<14:10,  1.57s/it]Scoring -> score_cm_eval.txt:   3%|▎         | 17/557 [00:28<14:08,  1.57s/it]Scoring -> score_cm_eval.txt:   3%|▎         | 18/557 [00:30<14:07,  1.57s/it]Scoring -> score_cm_eval.txt:   3%|▎         | 19/557 [00:32<14:06,  1.57s/it]Scoring -> score_cm_eval.txt:   4%|▎         | 20/557 [00:33<14:05,  1.57s/it]Scoring -> score_cm_eval.txt:   4%|▍         | 21/557 [00:35<14:04,  1.57s/it]Scoring -> score_cm_eval.txt:   4%|▍         | 22/557 [00:36<14:02,  1.58s/it]Scoring -> score_cm_eval.txt:   4%|▍         | 23/557 [00:38<14:01,  1.58s/it]Scoring -> score_cm_eval.txt:   4%|▍         | 24/557 [00:39<13:59,  1.58s/it]Scoring -> score_cm_eval.txt:   4%|▍         | 25/557 [00:41<13:59,  1.58s/it]Scoring -> score_cm_eval.txt:   5%|▍         | 26/557 [00:43<13:57,  1.58s/it]Scoring -> score_cm_eval.txt:   5%|▍         | 27/557 [00:44<13:57,  1.58s/it]Scoring -> score_cm_eval.txt:   5%|▌         | 28/557 [00:46<13:54,  1.58s/it]Scoring -> score_cm_eval.txt:   5%|▌         | 29/557 [00:47<13:52,  1.58s/it]Scoring -> score_cm_eval.txt:   5%|▌         | 30/557 [00:49<13:51,  1.58s/it]Scoring -> score_cm_eval.txt:   6%|▌         | 31/557 [00:51<13:49,  1.58s/it]Scoring -> score_cm_eval.txt:   6%|▌         | 32/557 [00:52<13:48,  1.58s/it]Scoring -> score_cm_eval.txt:   6%|▌         | 33/557 [00:54<13:46,  1.58s/it]Scoring -> score_cm_eval.txt:   6%|▌         | 34/557 [00:55<13:45,  1.58s/it]Scoring -> score_cm_eval.txt:   6%|▋         | 35/557 [00:57<13:44,  1.58s/it]Scoring -> score_cm_eval.txt:   6%|▋         | 36/557 [00:58<13:42,  1.58s/it]Scoring -> score_cm_eval.txt:   7%|▋         | 37/557 [01:00<13:41,  1.58s/it]Scoring -> score_cm_eval.txt:   7%|▋         | 38/557 [01:02<13:40,  1.58s/it]Scoring -> score_cm_eval.txt:   7%|▋         | 39/557 [01:03<13:41,  1.59s/it]Scoring -> score_cm_eval.txt:   7%|▋         | 40/557 [01:05<13:39,  1.59s/it]Scoring -> score_cm_eval.txt:   7%|▋         | 41/557 [01:06<13:39,  1.59s/it]Scoring -> score_cm_eval.txt:   8%|▊         | 42/557 [01:08<13:37,  1.59s/it]Scoring -> score_cm_eval.txt:   8%|▊         | 43/557 [01:10<13:35,  1.59s/it]Scoring -> score_cm_eval.txt:   8%|▊         | 44/557 [01:11<13:33,  1.59s/it]Scoring -> score_cm_eval.txt:   8%|▊         | 45/557 [01:13<13:32,  1.59s/it]Scoring -> score_cm_eval.txt:   8%|▊         | 46/557 [01:14<13:31,  1.59s/it]Scoring -> score_cm_eval.txt:   8%|▊         | 47/557 [01:16<13:29,  1.59s/it]Scoring -> score_cm_eval.txt:   9%|▊         | 48/557 [01:17<13:28,  1.59s/it]Scoring -> score_cm_eval.txt:   9%|▉         | 49/557 [01:19<13:28,  1.59s/it]slurmstepd: error: *** JOB 38957374 ON gl1526 CANCELLED AT 2025-12-27T12:44:38 ***
